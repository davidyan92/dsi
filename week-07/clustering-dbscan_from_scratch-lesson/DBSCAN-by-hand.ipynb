{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Programming DBSCAN from Scratch\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- Learn what the DBSCAN algorithm is\n",
    "- Understand the parameters that must be provided to DBSCAN\n",
    "- Program the DBSCAN algorithm from scratch using object oriented python\n",
    "- Build your own interactive visual in matplotlib to test your implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Density-based spatial clustering of applications with noise (DBSCAN)](#intro)\n",
    "- [DBSCAN algorithm](#algo)\n",
    "- [Building DBSCAN in parts](#parts)\n",
    "    - [Step 1: Create some fake clustered data](#step1)\n",
    "    - [Step 2: Make the skeleton of the DBSCAN class](#step2)\n",
    "    - [Step 3: Write the `fit` function](#step3)\n",
    "    - [Step 4: Write the function to find neighbors](#step4)\n",
    "    - [Step 5: Write the function to expand the clusters](#step5)\n",
    "- [Full DBSCAN code without comments](#fullcode)\n",
    "- [Plotting DBSCAN interactively](#interact)\n",
    "    - [Rewrite the plotting function to accept cluster labels](#rewrite)\n",
    "    - [Write a function that accepts `eps` and `min_samples` and fits DBSCAN](#plot-fit)\n",
    "    - [Write the interact function for the ipython widget](#int-func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Density-based spatial clustering of applications with noise (DBSCAN)\n",
    "\n",
    "---\n",
    "\n",
    "DBSCAN is a clustering algorithm that groups datapoints together based on \"density\". Nearby points get assigned to a common cluster, and outlier points get assigned to their own clusters. DBSCAN is effective and attractive for its simplicity and minimal pre-specified parameters.\n",
    "\n",
    "There are only two parameters that need to be specified for DBSCAN:\n",
    "\n",
    "    eps : a minimum distance between points that can define a \"connection\"\n",
    "    \n",
    "    min_samples : minimum number of points that a point needs to have \n",
    "                  as neighbors to define it as a \"core sample\"\n",
    "    \n",
    "**Core samples** are by design the points that lie internally within a cluster. \n",
    "\n",
    "**Non-core samples** do not meet the minimum required neighboring points, but are still connected to a cluster defined by a core sample or samples. Hence these points lie on the edges of a cluster.\n",
    "\n",
    "**Outliers** are points that do not meet the distance criteria to a cluster nor minimum neighbors to form a new cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='algo'></a>\n",
    "## The DBSCAN algorithm\n",
    "\n",
    "---\n",
    "\n",
    "The DBSCAN algorithm proceeds iteratively through the points, determining via the distance measure and minimum samples specified whether points are core samples, edge samples, or outliers.\n",
    "\n",
    "Here is the pseudocode algorithm below, which we will be coding up ourselves:\n",
    "\n",
    "\n",
    "```\n",
    "DBSCAN(D, eps, MinPts) {\n",
    "   C = 0\n",
    "   for each point P in dataset D {\n",
    "      if P is visited\n",
    "         continue next point\n",
    "      mark P as visited\n",
    "      NeighborPts = regionQuery(P, eps)\n",
    "      if sizeof(NeighborPts) < MinPts\n",
    "         mark P as NOISE\n",
    "      else {\n",
    "         C = next cluster\n",
    "         expandCluster(P, NeighborPts, C, eps, MinPts)\n",
    "      }\n",
    "   }\n",
    "}\n",
    "\n",
    "expandCluster(P, NeighborPts, C, eps, MinPts) {\n",
    "   add P to cluster C\n",
    "   for each point P' in NeighborPts { \n",
    "      if P' is not visited {\n",
    "         mark P' as visited\n",
    "         NeighborPts' = regionQuery(P', eps)\n",
    "         if sizeof(NeighborPts') >= MinPts\n",
    "            NeighborPts = NeighborPts joined with NeighborPts'\n",
    "      }\n",
    "      if P' is not yet member of any cluster\n",
    "         add P' to cluster C\n",
    "   }\n",
    "}\n",
    "\n",
    "regionQuery(P, eps)\n",
    "   return all points within P's eps-neighborhood (including P)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='parts'></a>\n",
    "\n",
    "## Building DBSCAN in parts\n",
    "\n",
    "---\n",
    "\n",
    "We can roll our own DBSCAN following the pseudcode above. Doing it piece by piece in parts will make it clear how the algorithm works.\n",
    "\n",
    "<a id='step1'></a>\n",
    "### Step 1: Create some fake clustered data\n",
    "\n",
    "sklearn has some nice data generation functions in its `sklearn.datasets` module. I've loaded a handful of them below. You can use them to create clustered data easily to test clustering algorithms.\n",
    "\n",
    "Generate clustered data and plot it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset generators:\n",
    "from sklearn.datasets import make_biclusters, make_blobs, make_circles, make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, bloby = make_blobs(n_samples=200, n_features=2, centers=4, cluster_std=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the fake data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step2'></a>\n",
    "### Step 2: Make the skeleton of the DBSCAN class\n",
    "\n",
    "Start laying out the blueprint for how DBSCAN will work. We'll need to start out:\n",
    "\n",
    "1. An `__init__` function to initialize the class with the `eps` and `min_samples` arguments.\n",
    "- A (for now empty) `fit` function that will run DBSCAN on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class skeleton:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step3'></a>\n",
    "### Step 3: Writing the `fit` function (equivalent to the `DBSCAN` function in pseudocode)\n",
    "\n",
    "Our `fit` function will follow the logic of the `DBSCAN` function in the pseudocode above (re-pasted here). In general, when building classes, think about what variables are best suited to be class attributes. It takes practice to get a feel for it.\n",
    "\n",
    "```\n",
    "DBSCAN(D, eps, MinPts) {\n",
    "   C = 0\n",
    "   for each point P in dataset D {\n",
    "      if P is visited\n",
    "         continue next point\n",
    "      mark P as visited\n",
    "      NeighborPts = regionQuery(P, eps)\n",
    "      if sizeof(NeighborPts) < MinPts\n",
    "         mark P as NOISE\n",
    "      else {\n",
    "         C = next cluster\n",
    "         expandCluster(P, NeighborPts, C, eps, MinPts)\n",
    "      }\n",
    "   }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can use sklearn's sklearn.metrics.pairwise.euclidean_distances \n",
    "# to find the distances between points for us, rather than re-coding\n",
    "# this ourselves.\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Add the fit function to the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step4'></a>\n",
    "### Step 4: Write the function to find neighbors\n",
    "\n",
    "We need to convert this function in the pseudocode to a class function:\n",
    "\n",
    "```\n",
    "regionQuery(P, eps)\n",
    "   return all points within P's eps-neighborhood (including P)\n",
    "```\n",
    "\n",
    "I've already named this `self.find_region_points(i)` so far, so we'll call it that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add the neighbor finder\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step5'></a>\n",
    "### Step 5: Write the function to expand the clusters.\n",
    "\n",
    "The final function (and the one that actually assigns our clusters) is defined by the pseudocode as:\n",
    "\n",
    "```\n",
    "expandCluster(P, NeighborPts, C, eps, MinPts) {\n",
    "   add P to cluster C\n",
    "   for each point P' in NeighborPts { \n",
    "      if P' is not visited {\n",
    "         mark P' as visited\n",
    "         NeighborPts' = regionQuery(P', eps)\n",
    "         if sizeof(NeighborPts') >= MinPts\n",
    "            NeighborPts = NeighborPts joined with NeighborPts'\n",
    "      }\n",
    "      if P' is not yet member of any cluster\n",
    "         add P' to cluster C\n",
    "   }\n",
    "}\n",
    "```\n",
    "\n",
    "Essentially the function takes a point id, the neighboring point ids, the cluster number, minimum distance, and minimum points, and figures out based on those components what cluster a point should be in. \n",
    "\n",
    "I've already pre-named this function in the `fit` function to be `expand_cluster(i, neighbors)`. We only need to pass in the current point and neighboring points because we're storing all of the other information the function needs as class attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a function to expand the clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fullcode'></a>\n",
    "## Full `DBSCAN` code without comments\n",
    "\n",
    "---\n",
    "\n",
    "Without the comments it is actually pretty concise. Again, DBSCAN is a powerful clustering algorithm but also appealing for its simplicity and the intuitive way it finds points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# See the solutions for the full code without comments!\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='interact'></a>\n",
    "## Plotting DBSCAN interactively\n",
    "\n",
    "---\n",
    "\n",
    "We can look at how the `eps` and `min_samples` parameters affect DBSCAN's decisions about assigning clusters. This is also a good opportunity to go over how to make interactive visualizations with ipython widgets.\n",
    "\n",
    "<a id='rewrite'></a>\n",
    "### Re-write the plotting function to accept cluster labels and color the points accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adjust the plotting function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='plot-fit'></a>\n",
    "### Write a function that accepts `eps` and `min_samples` as keyword arguments, fits DBSCAN, and calls the plotting function\n",
    "\n",
    "Don't pass `X` in to the function. We will just use the \"global\" X defined in the jupyter notebook earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add the arguments to the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='int-func'></a>\n",
    "### Make the \"interact\" function that creates the ipython widget\n",
    "\n",
    "Your interact function defines the sliders (or other inputs you want to be interactive) and then makes a call to `widgets.interact(function, *interactive objects)` where:\n",
    "\n",
    "- \"function\" is the function that takes the values coming out of the interactive slider objects (we wrote it just before: it takes `eps` and `min_samples`\n",
    "- The interactive objects in our case will be a `widgets.FloatSlider` for eps and a `widgets.IntSlider` for the min_samples.\n",
    "\n",
    "For more information see this handy notebook:\n",
    "\n",
    "https://github.com/ipython/ipywidgets/blob/master/docs/source/examples/Index.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the interact function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cluster_interact()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
