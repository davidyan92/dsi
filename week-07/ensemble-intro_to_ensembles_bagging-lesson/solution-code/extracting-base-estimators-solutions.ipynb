{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Extracting Base Estimators from Bagged Models Codealong\n",
    "\n",
    "_Authors: Joseph Nelson (SF)_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the breast cancer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking out some 'books' from the libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Converting data into a dataframe structure \n",
    "X = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "# Setting up our Y value as well\n",
    "y = pd.Series(data['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load required sklearn packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# More Books!!\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Make a train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train test split for fun\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create and fit a `BaggingClassifier` with a `DecisionTreeClassifier` base estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=0.5,\n",
       "         max_samples=0.5, n_estimators=5, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our classifier and our bag\n",
    "DT = DecisionTreeClassifier()\n",
    "BC = BaggingClassifier(base_estimator = DT, n_estimators =5, max_features = 0.5, max_samples = 0.5)\n",
    "\n",
    "# Fitting the Bag\n",
    "BC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Pull out a base estimator from the ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Getting our bags base model \n",
    "# We can only have one base model so our estimator models can not have varying parameters\n",
    "# The Random_state is more or less a reference seed.\n",
    "BC.base_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Pull out *all* the base estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=378203321, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=459756946, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=568997751, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=38061643, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=1044519573, splitter='best')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gettin the rest of our bags models.\n",
    "BC.estimators_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Get the features used in each of the bagged base estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([22,  8, 16, 13, 21,  1, 19,  0, 10,  7, 23,  2,  9, 20,  5]),\n",
       " array([ 2, 26,  9, 27,  1,  8,  0, 12, 23, 15, 16, 20, 29, 21, 10]),\n",
       " array([ 4, 14, 26,  6, 12, 19,  7,  8, 22, 13, 28, 25,  3, 18,  9]),\n",
       " array([20,  3, 12,  1, 21, 25,  5,  2, 17, 27, 18, 22, 13, 15, 14]),\n",
       " array([14,  0,  6, 16,  8, 27, 13, 11, 22, 19, 29, 20, 28, 12,  7])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the features in each of our bagged models.\n",
    "# Pretty much their index values of the list of feature names\n",
    "BC.estimators_features_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Create a list of the features used in the first base estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=378203321, splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the parameters for the first decision tree in our bag?\n",
    "BC.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22,  8, 16, 13, 21,  1, 19,  0, 10,  7, 23,  2,  9, 20,  5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the features used in the first model\n",
    "BC.estimators_features_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating a list of the selected features.\n",
    "sub_features = []\n",
    "for feature in BC.estimators_features_[0]:\n",
    "    sub_features.append(data['feature_names'][feature])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Get out the samples used in our first base estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting how many samples our bagging estimator used.\n",
    "jab = len(BC.estimators_samples_[0])\n",
    "jab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What are the samples used in the first model?\n",
    "samples = BC.estimators_samples_[0] \n",
    "\n",
    "# Creating a list to append the index of sample data that was use from x_train\n",
    "true_samples = []\n",
    "for bool_index in range(0,jab):\n",
    "\n",
    "    if samples[bool_index] == True:\n",
    "        true_samples.append(bool_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gotta set the X_train equal to a variable and reset the index\n",
    "data0  = X_train.reset_index(drop = True)\n",
    "\n",
    "#Using the True Samples from our DT to sub down x_train\n",
    "data2 = data0.ix[true_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.640</td>\n",
       "      <td>17.35</td>\n",
       "      <td>134.80</td>\n",
       "      <td>1335.0</td>\n",
       "      <td>0.09446</td>\n",
       "      <td>0.10760</td>\n",
       "      <td>0.15270</td>\n",
       "      <td>0.08941</td>\n",
       "      <td>0.1571</td>\n",
       "      <td>0.05478</td>\n",
       "      <td>...</td>\n",
       "      <td>25.37</td>\n",
       "      <td>23.17</td>\n",
       "      <td>166.80</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>0.1562</td>\n",
       "      <td>0.30550</td>\n",
       "      <td>0.41590</td>\n",
       "      <td>0.21120</td>\n",
       "      <td>0.2689</td>\n",
       "      <td>0.07055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.370</td>\n",
       "      <td>18.89</td>\n",
       "      <td>72.17</td>\n",
       "      <td>396.0</td>\n",
       "      <td>0.08713</td>\n",
       "      <td>0.05008</td>\n",
       "      <td>0.02399</td>\n",
       "      <td>0.02173</td>\n",
       "      <td>0.2013</td>\n",
       "      <td>0.05955</td>\n",
       "      <td>...</td>\n",
       "      <td>12.36</td>\n",
       "      <td>26.14</td>\n",
       "      <td>79.29</td>\n",
       "      <td>459.3</td>\n",
       "      <td>0.1118</td>\n",
       "      <td>0.09708</td>\n",
       "      <td>0.07529</td>\n",
       "      <td>0.06203</td>\n",
       "      <td>0.3267</td>\n",
       "      <td>0.06994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.110</td>\n",
       "      <td>22.54</td>\n",
       "      <td>87.02</td>\n",
       "      <td>529.4</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.14830</td>\n",
       "      <td>0.08705</td>\n",
       "      <td>0.05102</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>0.07310</td>\n",
       "      <td>...</td>\n",
       "      <td>14.55</td>\n",
       "      <td>29.16</td>\n",
       "      <td>99.48</td>\n",
       "      <td>639.3</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.44020</td>\n",
       "      <td>0.31620</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.4128</td>\n",
       "      <td>0.10760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.268</td>\n",
       "      <td>12.87</td>\n",
       "      <td>61.49</td>\n",
       "      <td>248.7</td>\n",
       "      <td>0.16340</td>\n",
       "      <td>0.22390</td>\n",
       "      <td>0.09730</td>\n",
       "      <td>0.05252</td>\n",
       "      <td>0.2378</td>\n",
       "      <td>0.09502</td>\n",
       "      <td>...</td>\n",
       "      <td>10.28</td>\n",
       "      <td>16.38</td>\n",
       "      <td>69.05</td>\n",
       "      <td>300.2</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>0.34410</td>\n",
       "      <td>0.20990</td>\n",
       "      <td>0.10250</td>\n",
       "      <td>0.3038</td>\n",
       "      <td>0.12520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.590</td>\n",
       "      <td>21.24</td>\n",
       "      <td>137.80</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>0.10850</td>\n",
       "      <td>0.16440</td>\n",
       "      <td>0.21880</td>\n",
       "      <td>0.11210</td>\n",
       "      <td>0.1848</td>\n",
       "      <td>0.06222</td>\n",
       "      <td>...</td>\n",
       "      <td>23.86</td>\n",
       "      <td>30.76</td>\n",
       "      <td>163.20</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.35970</td>\n",
       "      <td>0.51790</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.2480</td>\n",
       "      <td>0.08999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0       20.640         17.35          134.80     1335.0          0.09446   \n",
       "1       11.370         18.89           72.17      396.0          0.08713   \n",
       "2       13.110         22.54           87.02      529.4          0.10020   \n",
       "3        9.268         12.87           61.49      248.7          0.16340   \n",
       "4       20.590         21.24          137.80     1320.0          0.10850   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.10760         0.15270              0.08941         0.1571   \n",
       "1           0.05008         0.02399              0.02173         0.2013   \n",
       "2           0.14830         0.08705              0.05102         0.1850   \n",
       "3           0.22390         0.09730              0.05252         0.2378   \n",
       "4           0.16440         0.21880              0.11210         0.1848   \n",
       "\n",
       "   mean fractal dimension           ...             worst radius  \\\n",
       "0                 0.05478           ...                    25.37   \n",
       "1                 0.05955           ...                    12.36   \n",
       "2                 0.07310           ...                    14.55   \n",
       "3                 0.09502           ...                    10.28   \n",
       "4                 0.06222           ...                    23.86   \n",
       "\n",
       "   worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0          23.17           166.80      1946.0            0.1562   \n",
       "1          26.14            79.29       459.3            0.1118   \n",
       "2          29.16            99.48       639.3            0.1349   \n",
       "3          16.38            69.05       300.2            0.1902   \n",
       "4          30.76           163.20      1760.0            0.1464   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0            0.30550          0.41590               0.21120          0.2689   \n",
       "1            0.09708          0.07529               0.06203          0.3267   \n",
       "2            0.44020          0.31620               0.11260          0.4128   \n",
       "3            0.34410          0.20990               0.10250          0.3038   \n",
       "4            0.35970          0.51790               0.21130          0.2480   \n",
       "\n",
       "   worst fractal dimension  \n",
       "0                  0.07055  \n",
       "1                  0.06994  \n",
       "2                  0.10760  \n",
       "3                  0.12520  \n",
       "4                  0.08999  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Get out the target subsample for the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the y_train sub sample used.\n",
    "target = pd.DataFrame(y_train)\n",
    "target.reset_index(inplace = True, drop =True)\n",
    "target2 = target.ix[true_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Fit a decision tree equivalent to our first base estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting the Decision Tree in our First base model of our bagged classifier.\n",
    "DTC0 = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=472506830, splitter='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting the models X and Y values\n",
    "X0 = data2[sub_features]\n",
    "Y0 = target2[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=472506830, splitter='best')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "DTC0.fit(X0, Y0)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
