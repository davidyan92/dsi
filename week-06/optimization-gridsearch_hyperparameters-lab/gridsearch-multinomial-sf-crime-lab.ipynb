{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Practice Gridsearch and Multinomial Models with SF Crime Data\n",
    "\n",
    "_Authors: Joseph Nelson (DC), Sam Stack (DC)_\n",
    "\n",
    "---\n",
    "\n",
    "### Multinomial logistic regression models\n",
    "\n",
    "So far, we have been using logistic regression for binary problems where there are only two class labels. Logistic regression can be extended to dependent variables with multiple classes.\n",
    "\n",
    "There are two ways sklearn solves multiple-class problems with logistic regression: a multinomial loss or a \"one vs. rest\" (OvR) process where a model is fit for each target class vs. all the other classes. \n",
    "\n",
    "**Multinomial vs. OvR**\n",
    "- (both) 'k' classes\n",
    "- (M) 'k-1' models with 1 reference category\n",
    "- (OvR) 'k*(k-1)/2' models\n",
    "\n",
    "You will use the gridsearch in conjunction with multinomial logistic to optimize a model that predicts the category (type) of crime based on various features captured by San Francisco police departments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Necessary lab imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crime_csv = './datasets/sf_crime_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:\n",
    "crime_df = pd.read_csv(crime_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2. Create column for hour, month, and year from 'Dates' column.\n",
    "\n",
    "> *Hint: `pd.to_datetime` may or may not be helpful.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5/13/15 23:53\n",
       "1    5/13/15 23:53\n",
       "2    5/13/15 23:33\n",
       "3    5/13/15 23:30\n",
       "4    5/13/15 23:30\n",
       "Name: Dates, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A:\n",
    "crime_df.Dates[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = pd.to_datetime('5/13/15')\n",
    "dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crime_df['hour'] = crime_df.Dates.map(lambda x: x[-5:-3])\n",
    "crime_df['month'] = crime_df.Dates.map(lambda x: pd.to_datetime(x).month)\n",
    "crime_df['year'] = crime_df.Dates.map(lambda x: pd.to_datetime(x).year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Validate and clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18000 entries, 0 to 17999\n",
      "Data columns (total 12 columns):\n",
      "Dates         18000 non-null object\n",
      "Category      18000 non-null object\n",
      "Descript      18000 non-null object\n",
      "DayOfWeek     18000 non-null object\n",
      "PdDistrict    18000 non-null object\n",
      "Resolution    18000 non-null object\n",
      "Address       18000 non-null object\n",
      "X             18000 non-null float64\n",
      "Y             18000 non-null float64\n",
      "hour          18000 non-null object\n",
      "month         18000 non-null int64\n",
      "year          18000 non-null int64\n",
      "dtypes: float64(2), int64(2), object(8)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "crime_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make column names small caps\n",
    "crime_df.columns = [x.lower() for x in crime_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make category variables lower cap\n",
    "crime_df.category = crime_df.category.map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# A:\n",
    "# remove the year column, zero variance\n",
    "crime_df.drop(labels=['year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4. Set up a target and predictor matrix for predicting violent crime vs. non-violent crime vs. non-crimes.\n",
    "\n",
    "**Non-Violent Crimes:**\n",
    "- bad checks\n",
    "- bribery\n",
    "- drug/narcotic\n",
    "- drunkenness\n",
    "- embezzlement\n",
    "- forgery/counterfeiting\n",
    "- fraud\n",
    "- gambling\n",
    "- liquor\n",
    "- loitering \n",
    "- trespass\n",
    "\n",
    "**Non-Crimes:**\n",
    "- non-criminal\n",
    "- runaway\n",
    "- secondary codes\n",
    "- suspicious occ\n",
    "- warrants\n",
    "\n",
    "**Violent Crimes:**\n",
    "- everything else\n",
    "\n",
    "\n",
    "\n",
    "**What type of model do you need here? What should your \"baseline\" category be?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['warrants', 'other offenses', 'larceny/theft', 'vehicle theft',\n",
       "       'vandalism', 'non-criminal', 'robbery', 'assault', 'weapon laws',\n",
       "       'burglary', 'suspicious occ', 'drunkenness',\n",
       "       'forgery/counterfeiting', 'drug/narcotic', 'stolen property',\n",
       "       'secondary codes', 'trespass', 'missing person', 'fraud',\n",
       "       'kidnapping', 'runaway', 'driving under the influence',\n",
       "       'sex offenses forcible', 'prostitution', 'disorderly conduct',\n",
       "       'arson', 'family offenses', 'liquor laws', 'bribery',\n",
       "       'embezzlement', 'assualt', 'suicide', 'loitering', 'trespassing',\n",
       "       'sex offenses non forcible', 'extortion', 'gambling', 'bad checks'], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A:\n",
    "# Baseline category is Non-Violent Crimes\n",
    "crime_df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_violent_crimes = ['bad checks','bribery','drug/narcotic','drunkenness','embezzlement','forgery/counterfeiting',\n",
    "                     'fraud','gambling','liquor laws','loitering','trespassing']\n",
    "\n",
    "non_crimes = ['non-criminal','runaway','secondary codes','suspicious occ','warrants']\n",
    "\n",
    "violent_crimes = [x for x in crime_df.category.unique() if x not in non_violent_crimes and x not in non_crimes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df.category = crime_df.category.map(lambda x: 2 if x in non_violent_crimes else 1 if x in non_crimes else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Standardize the predictor matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category ~ dates + descript + dayofweek + pddistrict + resolution + address + x + y + hour + month\n"
     ]
    }
   ],
   "source": [
    "# A:\n",
    "f = 'category ~ ' + ' + '.join([col for col in crime_df.columns if col != 'category'])\n",
    "print(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Find the optimal hyperparameters (optimal regularization) to predict your crime categories.\n",
    "\n",
    "> **Note:** Gridsearching can be done with `GridSearchCV` or `LogisticRegressionCV`. They operate differently - the gridsearch object is more general and can be applied to any model. The `LogisticRegressionCV` is specific to tuning the logistic regression hyperparameters. I recommend the logistic regression one, but the downside is that lasso and ridge must be searched separately.\n",
    "\n",
    "**Reference for logistic regression regularization hyperparameters:**\n",
    "- `solver`: algorithm used for optimization (relevant for multiclass)\n",
    "    - Newton-cg - Handles Multinomial Loss, L2 only\n",
    "    - Sag - Handles Multinomial Loss, Large Datasets, L2 Only, Works best on sclaed data\n",
    "    - lbfgs - Handles Multinomial Loss, L2 Only\n",
    "    - Liblinear - Small Datasets, no Warm Starts\n",
    "- `Cs`: Regularization strengths (smaller values are stronger penalties)\n",
    "- `cv`: vross-validations or number of folds\n",
    "- `penalty`: `'l1'` - LASSO, `'l2'` - Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "# fit model with five folds and lasso regularization\n",
    "# use Cs=15 to test a grid of 15 distinct parameters\n",
    "# remember: Cs describes the inverse of regularization strength\n",
    "\n",
    "# logreg_cv = LogisticRegressionCV(solver='liblinear', \n",
    "#                                  Cs=[1,5,10], \n",
    "#                                  cv=5, penalty='l1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split data into training and testing with 50% in testing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gridsearch hyperparameters for the training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the best parameters for each target class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build three logisitic regression models using the best parameters for each target class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Build confusion matrices for the models above\n",
    "- Use the holdout test data from the train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Print classification reports for your three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Describe the metrics in the classification report.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
