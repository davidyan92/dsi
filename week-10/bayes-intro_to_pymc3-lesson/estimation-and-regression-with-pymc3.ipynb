{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Bayesian Estimation and Regression with `pymc3`\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- Learn how to use pymc3 to fit Bayesian estimation models\n",
    "- Run the Bayesian alternative to a t-test using pymc3\n",
    "- Plot and interpret the results of pymc3 models\n",
    "- Construct a Bayesian regression using pymc3\n",
    "- Use the patsy-style formula syntax to build a pymc3 regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Introduction](#intro)\n",
    "- [Enter `pymc3`](#pymc3)\n",
    "- [Load the Starcraft data](#data)\n",
    "- [Alternative to t-testing using Bayesian estimation](#ttest)\n",
    "    - [Get the APM values for 19 and 26 year olds](#load)\n",
    "    - [Perform a Frequentist t-test of the mean APM difference between groups.](#freq-ttest)\n",
    "    - [Set up a Bayesian model with priors on the mean APMs](#priors)\n",
    "    - [Construct the prior distributions on the means](#construct-priors)\n",
    "    - [Construct the prior distributions on the standard deviations](#std-priors)\n",
    "    - [Set up the APM distributions for the two groups](#apm-dists)\n",
    "    - [Tracking additional metrics](#metrics)\n",
    "    - [Fitting the `pymc3` model](#fit)\n",
    "    - [Plotting the posteriors and metric distributions](#plotting)\n",
    "- [Bayesian regression with `pymc3`](#reg)\n",
    "    - [Set up variables to perform an age vs. APM regression](#age-vs-apm)\n",
    "    - [Set up the Bayesian regression model](#bayes-model)\n",
    "    - [Plot the posteriors using `pm.traceplot`](#traceplot)\n",
    "- [Using a patsy-style formula to specify a `pymc3` model](#formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "---\n",
    "\n",
    "With `pymc3` we can perform the Bayesian counterparts of Frequentist models we have studied. In this codealong lesson we will start incrementally: first replacing the Frequentist t-test with Bayesian estimation and then performing a Bayesian regression with a single predictor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pymc3'></a>\n",
    "## Enter `pymc3`\n",
    "---\n",
    "\n",
    "The `pymc3` is the Bayesian modeling package we will be using. It is a powerful and flexible architecture for performing a huge variety of Bayesian analyses. We will only be scratching the surface today.\n",
    "\n",
    "> **Note:** There is also `pymc` (or pymc2) which has a different syntax. pymc2 is (in my opinion) harder for beginners to Bayesian statistics to understand; pymc3 bridges the gap better for those who are more familiar with constructing models using Frequentist style models/syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data'></a>\n",
    "### Load the Starcraft dataset\n",
    "---\n",
    "\n",
    "You may be familiar with this dataset. It has records of different player statistics in competitive Starcraft. There are a variety of columns that are described in detail within the `description.txt` file contained inside the `./datasets/` folder.\n",
    "\n",
    "For the examples in this lab, I will be using APM (actions per minute) and Age, but I in the following lab you will get the chance to look at other variables as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "star = pd.read_csv('./datasets/SkillCraft1_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ttest'></a>\n",
    "## Alternative to t-testing using Bayesian estimation\n",
    "---\n",
    "\n",
    "[This example is adapted from the documentation here.](http://pymc-devs.github.io/pymc3/notebooks/BEST.html) \n",
    "\n",
    "> *Note: In that example the Student t distribution is used instead of the normal distribution like I use below. This is more appropriate, but more complicated due to the parameterization of the t-distribution. If you're feeling bold try doing this with the t-distribution like in the documentation!\n",
    "\n",
    "In the following code, I will be using Bayesian posterior estimation to look at the difference in APM between 19 year old players and 26 year old players.\n",
    "\n",
    "### The Frequentist strategy\n",
    "In Frequentist statistics, calculating the mean difference between groups is typically done with a t-test. In a t-test we state a null hypothesis (H0) that there is no diffference between groups, then evaluate the probability that we could have gotten this data when the null hypothesis is true.\n",
    "\n",
    "The de-facto standard for statistically comparing two (or more) samples is to use a statistical test. This involves expressing a null hypothesis, which typically claims that there is no difference between the groups, and using a chosen test statistic to determine whether the distribution of the observed data is plausible under the hypothesis. This rejection occurs when the calculated test statistic is higher than some pre-specified threshold value.\n",
    "\n",
    "### The Bayesian strategy\n",
    "The Bayesian approach for evaluating differences between groups is \"estimation\" rather than \"testing\". Instead of asking \"are the two groups different?\", we instead ask \"_how_ different are the two groups?\" This is the subtle difference in estimation as opposed to testing. We are measuring the extent of the difference between the groups, whether it be zero or any other value.\n",
    "\n",
    "For a more detailed treatment feel free to read the documentation linked above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load'></a>\n",
    "### Get the APM for 19 and 26 year olds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the mean for the two groups and the empirical difference between means.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='freq-ttest'></a>\n",
    "### Perform a Frequentist t-test of the mean APM difference between groups.\n",
    "\n",
    "What is the null hypothesis? What is the alternative hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the t-statistic for the test on the t-distribution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the p-value?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='priors'></a>\n",
    "### Set up the bayesian model with priors on mean APMs\n",
    "\n",
    "Next we'll go through the steps of the Bayesian estimation of the difference between means using `pymc3`.\n",
    "\n",
    "First we find the mean and standard deviation of APM regardless of age group. We can going to use these values to inform our prior belief about APM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='construct-priors'></a>\n",
    "### Construct the prior distributions on the means\n",
    "\n",
    "> **Note**: `pymc3` sets up models using the Python `with ... :` syntax.\n",
    "\n",
    "The first thing we are going to set up is our prior belief about the mean APM for our 19 year olds and 26 year olds. _These are not fixed values,_ but rather normal distributions covering a range of possible values for the mean APM for each group with varying likelihoods.\n",
    "\n",
    "We are going to set up the normal distributions to both take the overall mean and standard deviation of the actions per minute for all players. In other words, our prior belief for each group's mean APM is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='std-priors'></a>\n",
    "### Priors on standard deviations\n",
    "\n",
    "What we set up before are the prior distributions for the _means_ of APM for the two age groups, but we can also set up priors on the standard deviations for APM for each group.\n",
    "\n",
    "Our standard deviation priors can be \"uninformative\": uniformly distributed from close to 0 up to 100. We are saying that we believe all standard deviations in those ranges to be equally likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='apm-dists'></a>\n",
    "### Set up the APM distributions for the two groups\n",
    "\n",
    "Now that we have our prior beliefs about the mean and standard deviation of APM for each age group, we can construct what will be the posterior distributions for the APMs after \"observing\" the data.\n",
    "\n",
    "For each group we set up a `pm.Normal` distribution to represent the posterior distributions of APM. The mean `mu=` will be our prior belief distribution of the mean for that group. Likewise the `sd=` will be the prior distribution for standard deviation of APM for that group. \n",
    "\n",
    "Lastly, we provide the posteriors vectors of data for the `observed=` parameter. This is the actual, measured APM data. When we \"fit\" this model (using MCMC or another sampling strategy under the hood), the posterior distributions will be updated according to our prior beliefs and our data – just like in Bayes formula!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='metrics'></a>\n",
    "### Tracking additional metrics\n",
    "\n",
    "The last thing we'll do before fitting the model is define some distributions that will make it easier for us to evaluate the difference between mean APMs of the two groups. \n",
    "\n",
    "`pm.Deterministic` distributions are defined from other distributions in the model. For example, we can set up `diff_of_means` to be defined by `group19_mean - group26_mean`, making this a distribution of the differences between means between groups as the posteriors are iteratively fit/estimated.\n",
    "\n",
    "We can also set up a distribution for the efect size by taking the difference between means and dividing by the pooled standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fit'></a>\n",
    "### Fitting the `pymc3` model\n",
    "\n",
    "When we call `trace = pm.sample(...)` we are starting a sampling process to estimate the posterior distribution. `pymc3` has the option to do MCMC, but defaults to the NUTS sampler. NUTS stands for No U-Turn Sampler and is a state-of-the-art posterior estimation algorithm.\n",
    "\n",
    "The \"trace\" is a collection of all the values on the posterior distribution \"visited\" during the sampling procedure. The values in the trace define the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plotting'></a>\n",
    "### Plotting the posteriors and metric distributions\n",
    "\n",
    "`pymc3` comes with convenient methods for plotting posteriors. Below we plot our posterior means and standard deviations. The relevant statistics about the distributions are automatically added to the plots.\n",
    "\n",
    "The HPD is the Highest Posterior Density interval. This gives us a Bayesian \"credible interval\" which is the corollary to the Frequentist confidence interval. The 95% HPD says that the 95% highest density points on the distribution fall within that range.\n",
    "\n",
    "**Take a look at the first element of the `trace`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the `pm.plot_posterior` function to look at the posterior distributions for the group means and standard deviations.**\n",
    "\n",
    "> **Note:** It is common to slice off the initial portion of the trace. This is known as the \"burn-in\". The sampling procedure often starts far away from the correct estimates, and so slicing off the beginning can get rid of the cruft. It is also common to not take every sample, but skip every two or three. I am not doing that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the posteriors of our metric distributions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The `pm.summary` function can also display a text representation of this information:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reg'></a>\n",
    "## Bayesian regression with `pymc3`\n",
    "---\n",
    "\n",
    "With `pymc3`, the sky is the limit. Let's move on to something a little more complicated: Bayesian regressions.\n",
    "\n",
    "> *Note: [This example is modeled after the generalized linear model (GLM) instructions in the pymc3 documentation.](http://pymc-devs.github.io/pymc3/notebooks/GLM-linear.html)*\n",
    "\n",
    "What are the benefits to taking a Bayesian approach to regression modeling? Just like in our estimation of means per group, when we perform regression with Bayesian statistics we will get out posterior *distributions* on our intercept and coefficients. \n",
    "\n",
    "This is a big difference from the point estimates coming out of the Frequentist regression: not only do we have the most likely value for the coefficients (the MAP estimates), we can see the range of possibilities given our prior and observed data. \n",
    "\n",
    "---\n",
    "\n",
    "<a id='age-vs-apm'></a>\n",
    "### Set up variables to perform an age vs. APM regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot out the age vs. apm values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bayes-model'></a>\n",
    "### Setting up the Bayesian regression model\n",
    "\n",
    "Like before, we will construct our model with the `with pm.Model() ...` syntax. \n",
    "\n",
    "We have three prior distributions in this case that will be updated to posteriors given our observed data:\n",
    "\n",
    "1. `apm_std`: which will be our prior belief about the standard deviation of APM values. In this case I am setting it to be uniform (uninformative) between `0.0001`, and `1000.`\n",
    "- `intercept`: a normal distribution for the range of possible values of the intercept.\n",
    "- `age_beta`: a normal distribution for the range of possible values of the age coefficient.\n",
    "\n",
    "We set up a `likelihood` distribution that is also normal, representing the distribution of the data (APM) given our predictor. The mean of the likelihood is defined like a regression formula: our intercept distribution plus the age values times our age beta distribution. We give the `apm_std` uniform prior as the standard deviation. Lastly, the observed values, or data, will be the APM values.\n",
    "\n",
    "What will happen here as we sample from the posterior is that more likely values (as defined by the `mu=` regression-style definition) will be \"visited\" more often. The intercept and age_beta distributions will have more values visited in places where they result in higher likelihood estimates.\n",
    "\n",
    "`pm.find_MAP()` tries to find good starting values for our sampling procedure so that we don't have to run it for as many iterations to get a good posterior representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='traceplot'></a>\n",
    "### Plot the posteriors using `pm.traceplot`\n",
    "\n",
    "The traceplot function can also plot our posteriors, as well as a graph of the actual traces for each distribution. These traces represent the points visited by the sampling algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='formula'></a>\n",
    "## Setting up a model using a patsy-style formula\n",
    "---\n",
    "\n",
    "`pymc3` also provides a convenience function `pm.glm.glm(...` which takes a patsy-style formula definition and the dataframe, then automatically constructs the distributions required to solve the Bayesian regression. Pretty nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lastly, you can plot out different possible regression lines with `pm.glm.plot_posterior_predictive`.**\n",
    "\n",
    "This function takes:\n",
    "\n",
    "- the trace (MCMC samples)\n",
    "- the number of samples you want to draw out and plot\n",
    "- an `lm=` argument that will be a function defining how the regression line will be fit using an x value and the sample\n",
    "- an `eval=` argument that will be the x-values `lm` is evaluated over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
