{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Timeseries Forecasting with LSTM on Stock Data\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "In this lab you will practice building LSTMs with Keras to fit and predict on timeseries data. In particular, you will be pulling down stock price data using a matplotlib package (code provided).\n",
    "\n",
    "This lab mirrors in large part the Keras LSTM code in the lecture, so please see that for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import the required Keras packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pull down the stock price data using `matplotlib.finance`\n",
    "\n",
    "The code to pull the stock data is provided for you. This code will pull the daily close prices for a variety of companies in the year 2010. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.finance import quotes_historical_yahoo_ochl\n",
    "import datetime\n",
    "\n",
    "symbol_dict = {\n",
    "    'TOT': 'Total',\n",
    "    'XOM': 'Exxon',\n",
    "    'CVX': 'Chevron',\n",
    "    'COP': 'ConocoPhillips',\n",
    "    'VLO': 'Valero Energy',\n",
    "    'MSFT': 'Microsoft',\n",
    "    'IBM': 'IBM',\n",
    "    'TWX': 'Time Warner',\n",
    "    'CMCSA': 'Comcast',\n",
    "    'CVC': 'Cablevision',\n",
    "    'YHOO': 'Yahoo',\n",
    "    'DELL': 'Dell',\n",
    "    'HPQ': 'HP',\n",
    "    'AMZN': 'Amazon',\n",
    "    'TM': 'Toyota',\n",
    "    'CAJ': 'Canon',\n",
    "    'MTU': 'Mitsubishi',\n",
    "    'SNE': 'Sony',\n",
    "    'F': 'Ford',\n",
    "    'HMC': 'Honda',\n",
    "    'NAV': 'Navistar',\n",
    "    'NOC': 'Northrop Grumman',\n",
    "    'BA': 'Boeing',\n",
    "    'KO': 'Coca Cola',\n",
    "    'MMM': '3M',\n",
    "    'MCD': 'Mc Donalds',\n",
    "    'PEP': 'Pepsi',\n",
    "    'MDLZ': 'Kraft Foods',\n",
    "    'K': 'Kellogg',\n",
    "    'UN': 'Unilever',\n",
    "    'MAR': 'Marriott',\n",
    "    'PG': 'Procter Gamble',\n",
    "    'CL': 'Colgate-Palmolive',\n",
    "    'GE': 'General Electrics',\n",
    "    'WFC': 'Wells Fargo',\n",
    "    'JPM': 'JPMorgan Chase',\n",
    "    'AIG': 'AIG',\n",
    "    'AXP': 'American express',\n",
    "    'BAC': 'Bank of America',\n",
    "    'GS': 'Goldman Sachs',\n",
    "    'AAPL': 'Apple',\n",
    "    'SAP': 'SAP',\n",
    "    'CSCO': 'Cisco',\n",
    "    'TXN': 'Texas instruments',\n",
    "    'XRX': 'Xerox',\n",
    "    'LMT': 'Lookheed Martin',\n",
    "    'WMT': 'Wal-Mart',\n",
    "    'WBA': 'Walgreen',\n",
    "    'HD': 'Home Depot',\n",
    "    'GSK': 'GlaxoSmithKline',\n",
    "    'PFE': 'Pfizer',\n",
    "    'SNY': 'Sanofi-Aventis',\n",
    "    'NVS': 'Novartis',\n",
    "    'KMB': 'Kimberly-Clark',\n",
    "    'R': 'Ryder',\n",
    "    'GD': 'General Dynamics',\n",
    "    'RTN': 'Raytheon',\n",
    "    'CVS': 'CVS',\n",
    "    'CAT': 'Caterpillar',\n",
    "    'DD': 'DuPont de Nemours'}\n",
    "\n",
    "symbols, names = np.array(list(symbol_dict.items())).T\n",
    "\n",
    "# Choose a time period (2008 crash in middle!)\n",
    "d1 = datetime.datetime(2010, 1, 1)\n",
    "d2 = datetime.datetime(2011, 1, 1)\n",
    "\n",
    "quotes = [quotes_historical_yahoo_ochl(symbol, d1, d2, asobject=True)\n",
    "          for symbol in symbols]\n",
    "\n",
    "stock_close = {symb:q.close for symb, q in zip(symbols, quotes)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Convert the stock closes to a dataframe and perform first-order differencing\n",
    "\n",
    "This converts the data into daily changes in stock price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Select a handful of stock symbols to look at and subset the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Normalize the data to the range -1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Split the data into training and testing subsets\n",
    "\n",
    "Make sure the test set is all future data (timepoints beyond the training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Create an X and Y matrix where the predictor matrix X are the changes lagged one behind Y.\n",
    "\n",
    "A cool aspect of LSTMs and neural network architectures in general is that it is trivial to fit models with multiple outputs.\n",
    "\n",
    "Here our target will be a *matrix* of tomorrows price changes, and the predictors will be a matrix of todays stock changes. Thus we are going to optimize the neural network to minimize the error predicting the next stock change on all of the stocks at the same time!\n",
    "\n",
    "Create the X and Y below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Reshape the training and testing X to be 3D\n",
    "\n",
    "Recall that the LSTM takes a tensor in format:\n",
    "\n",
    "    [observations, timesteps, features]\n",
    "    \n",
    "We lagged this only 1, so we will only have 1 timestep per feature (we will be using a stateful LSTM for fitting so we don't actually need more than 1 timestep).\n",
    "\n",
    "> *Hint: the `np.reshape` function can add the 3rd dimension to your data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Build a Keras LSTM model\n",
    "\n",
    "Below is some code that will build an LSTM model for this forecasting problem:\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "# Remember: \"batch_input_shape\" and specify the batch size\n",
    "model.add(LSTM(32, batch_input_shape=(1, 1, Xtrain.shape[2]), stateful=True))\n",
    "model.add(Dense(Xtrain.shape[2]))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "Some things to note:\n",
    "- The `stateful=True` indicates that our LSTM layer is stateful and will need to be manually reset. This allows us to feed in all the observations sequentially and allow the LSTM to (possibly) find signal in temporal patterns.\n",
    "- We have 32 LSTM neurons. The `batch_input_shape=(1, 1, Xtrain.shape[2])` specifies the expected input to this layer. There will be 1 observation at a time, with 1 timestep, and as many features as there are in Xtrain.\n",
    "- The `model.add(Dense(Xtrain.shape[2]))` adds the final output layer with as many output neurons as there are features. When we fit the model we will be predicting the matrix Y that has the same number of columns. This is the portion that allows us to fit on multiple outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Fit the stateful LSTM model\n",
    "\n",
    "Below is code to help you fit the model outlined above:\n",
    "\n",
    "```python\n",
    "for i in range(100):\n",
    "    if (i % 5) == 0:\n",
    "        print 'ITER:', i\n",
    "        model.fit(Xtrain, Ytrain, nb_epoch=1, batch_size=1, verbose=1, shuffle=False)\n",
    "    else:\n",
    "        model.fit(Xtrain, Ytrain, nb_epoch=1, batch_size=1, verbose=0, shuffle=False)\n",
    "    model.reset_states()\n",
    "```\n",
    "\n",
    "Here we will iterate over the entire training data 100 times. Each time we will fit the model without shuffling the data, feeding in single observations sequentially (batch_size=1).\n",
    "\n",
    "The if-else statement inside allows us to print out every 5 iterations. Notice the `model.reset_states()`. This is where we manually clear the internal state of the LSTM neurons after each pass through the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Plot the forecast on the testing data\n",
    "\n",
    "Plot out the testing data and the forecast from the LSTM prediction. You will need to predict on the X test data.\n",
    "\n",
    "Remember that the LSTM is now making a prediction for each of the stocks, so the prediction will be a matrix. To plot an individual stock, you will need to pull out the column corresponding to that stock.\n",
    "\n",
    "> **Note:** as this is a fairly challenging plotting problem, I have provided template plotting code below. It is similar to the plotting code outlined in the LSTM forecasting lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# def plot_all(model, Xtrain, Xtest, Ytest, bdfn, bank_names):\n",
    "#     train_hat = model.predict(Xtrain, batch_size=1)\n",
    "#     model.reset_states()\n",
    "#     test_hat = model.predict(Xtest, batch_size=1)\n",
    "#     model.reset_states()\n",
    "    \n",
    "#     train_plot = np.empty_like(bdfn.values)\n",
    "#     train_plot[:, :] = np.nan\n",
    "#     train_plot[1:Xtrain.shape[0]+1, :] = train_hat\n",
    "    \n",
    "#     test_plot = np.empty_like(bdfn.values)\n",
    "#     test_plot[:, :] = np.nan\n",
    "#     test_plot[-Xtest.shape[0]:, :] = test_hat\n",
    "    \n",
    "#     fig, axarr = plt.subplots(Ytest.shape[1], 1, figsize=(12,24))\n",
    "    \n",
    "#     for i in range(Ytest.shape[1]):\n",
    "#         axarr[i].plot(bdfn.iloc[:,i], color='grey', alpha=0.7)\n",
    "#         axarr[i].plot(train_plot[:,i])\n",
    "#         axarr[i].plot(test_plot[:,i])\n",
    "#         test_r2 = r2_score(Ytest[:,i], test_hat[:,i])\n",
    "#         axarr[i].set_title(bank_names[bdfn.columns[i]]+' test R2: '+str(test_r2))\n",
    "        \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. [Bonus] Build another LSTM model of your choice.\n",
    "\n",
    "There are many ways you could change things up. Consider:\n",
    "1. Changing the stocks in the predictor matrix or target.\n",
    "2. Adding layers to the neural network architecture (check out the Keras documentation or examples!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
