{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Sentiment Analysis of Movie Reviews with Spacy and VADER\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand the goal of basic sentiment analysis.\n",
    "- Calculate sentiment scores manually using a reviews dataset and scores tagged by word.\n",
    "- Practice using the spacy parser to get out part of speech tags from text.\n",
    "- Fit a model using sentiment and grammar features.\n",
    "- Use the VADER sentiment analyzer to get out more accurate sentiment scores and compare the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Introduction to sentiment analysis](#intro)\n",
    "- [Load the word sentiment dataset](#load-sen)\n",
    "    - [Engineer objectivity and positive difference scores](#adj-scores)\n",
    "    - [Put scores in a part of speech dictionary](#pos-dict)\n",
    "- [Load the rotten tomatoes review dataset](#rt-reviews)\n",
    "    - [Restrict reviews to valid lengths and ratings](#subset)\n",
    "- [Import spacy](#spacy)\n",
    "    - [Parse all the quotes using spacy's multithreaded parser](#multi)\n",
    "- [Part of speech features](#pos-features)\n",
    "- [Assign sentiment scores](#assign)\n",
    "- [Print out the most positive and most negative reviews](#print-most)\n",
    "- [Print out the most objective and most subjective reviews](#print-most-obj)\n",
    "- [Build a model to classify fresh vs. rotten with the sentiment and grammar features](#model)\n",
    "- [User the VADER library to get better sentiment scores](#vader)\n",
    "    - [Build a model using the VADER sentiment features](#vader-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "\n",
    "## Introduction to sentiment analysis\n",
    "---\n",
    "\n",
    "Sentiment analysis is one of the most popular topics in NLP. Most commonly it is the quantification of text into valence and subjectivity scores.\n",
    "\n",
    "First we will load in a dataset of pre-coded sentiment scores for positivity and negativity on words. These words are also tagged with their part of speech in the sentence. We can use these valence scores to evaluate the sentiment of rottentomatoes movie reviews. Many packages such as TextBlob come pre-packaged with sentiment scores for words after parsing text, but doing the sentiment parsing manually will show you how it can be done without any \"magic\".\n",
    "\n",
    "We will also explore a more advanced sentiment analysis library in python: [VADER](https://github.com/cjhutto/vaderSentiment). We can parse the sentiment of the movie reviews using this package and compare it to our more basic method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load-sen'></a>\n",
    "\n",
    "## Load the word sentiment dataset\n",
    "---\n",
    "\n",
    "Below we will load in some pre-tagged positive and negative valence scores for a dictionary of words. Each row of the dataset contains the part of speech, the word, the positive score, and the negative score for the word. A word may appear more than once if it can appear with different part of speech tags. \n",
    "\n",
    "These scores are designed so that we can also derive the *objectivity score* of the word from the positive and negative scores.\n",
    "\n",
    "Objectivity is calculated: \n",
    "\n",
    "    1. - (positive_score + negative_score)\n",
    "\n",
    "Thus if a score has zero positive score and negative score it is completely objective. If a score has, for example, 0.5 positive and 0.5 negative, it may not be any more positive than negative but we can tell that it is subjective (objectivity = 0.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sen = pd.read_csv('./datasets/sentiment_words_simple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:\n",
    "\n",
    "sen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make the part of speech tags uppercase (this will come in handy later when we use Spacy).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='adj-scores'></a>\n",
    "\n",
    "### Engineer objectivity and positive difference scores\n",
    "\n",
    "Since subjective vs. objective is embedded in the positive and negative scores, we should extract this and convert the positive and negative into a relative difference scores.\n",
    "\n",
    "**Calculate two new scores:**\n",
    "\n",
    "    objectivity = 1. - (pos_score + neg_score)\n",
    "    pos_vs_neg = pos_score - neg_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>objectivity</th>\n",
       "      <th>pos_vs_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>.22-caliber</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>.22-calibre</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>.22_caliber</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>.22_calibre</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>.38-caliber</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pos         word  pos_score  neg_score  objectivity  pos_vs_neg\n",
       "0  ADJ  .22-caliber        0.0        0.0          1.0         0.0\n",
       "1  ADJ  .22-calibre        0.0        0.0          1.0         0.0\n",
       "2  ADJ  .22_caliber        0.0        0.0          1.0         0.0\n",
       "3  ADJ  .22_calibre        0.0        0.0          1.0         0.0\n",
       "4  ADJ  .38-caliber        0.0        0.0          1.0         0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pos-dict'></a>\n",
    "\n",
    "### Put scores in a part of speech dictionary\n",
    "\n",
    "The dictionary format of the data will be much easier to index using our parsing functions later on. Create a dictionary where the keys are the four part of speech tags:\n",
    "\n",
    "    ADJ\n",
    "    NOUN\n",
    "    VERB\n",
    "    ADV\n",
    "\n",
    "For each key, store a dictionary that contains all of the words for that part of speech with their objectivity and positive vs. negative scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rt-reviews'></a>\n",
    "\n",
    "## Load the rotten tomatoes reviews dataset\n",
    "\n",
    "---\n",
    "\n",
    "This dataset has:\n",
    "    \n",
    "    critic: critic's name\n",
    "    fresh: fresh vs. rotten rating\n",
    "    imdb: code for imdb\n",
    "    publication: where the review was published\n",
    "    quote: the review snippet\n",
    "    review_date: date of review\n",
    "    rtid: rottentomatoes id\n",
    "    title: name of movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt = pd.read_csv('./datasets/rt_critics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='subset'></a>\n",
    "\n",
    "### Restrict data to reviews with valid ratings and reviews over 10 words long\n",
    "\n",
    "Also clean up the reviews, making a column with the case and punctuation removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='spacy'></a>\n",
    "\n",
    "## Import spacy\n",
    "\n",
    "---\n",
    "\n",
    "The spacy package is the current gold standard for parsing the grammatical structure of text (aside from neural network architectures). We are going to use it to find the part of speech tags for the review words. \n",
    "\n",
    "Once we have parsed the tags with spacy, we can assign objectivity and valence scores by finding the match in our sentiment dataset.\n",
    "\n",
    "Code for loading spacy:\n",
    "- pip install spacy\n",
    "- python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "en_nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parse a single quote:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:\n",
    "tmp = en_nlp(rt.qt.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print out the part of speech tags for each word in the quote:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='multi'></a>\n",
    "### Parse all the quotes using spacy's multithreaded parser\n",
    "\n",
    "Parsing a lot of text can take quite awhile. Luckily spacy comes with multithreading functionality to speed up the process considerably. Below is code that will parse the quotes across multiple threads and assign them to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pos-features'></a>\n",
    "\n",
    "## Create features with part of speech proportions\n",
    "\n",
    "---\n",
    "\n",
    "With our spacy parsed reviews, we have a lot of feature engineering potential even before we get to sentiment. Something simple we could do is calculate the proportion of words in the quote that have each part of speech tag. We can try using these as predictors in a model later.\n",
    "\n",
    "**Find all the unique part of speech categories in the reviews.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the proportion columns for each part of speech.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iterate through the reviews and calculate the proportions of each part of speech tag.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assign'></a>\n",
    "\n",
    "## Assign sentiment scores\n",
    "---\n",
    "\n",
    "We will now use the parsed reviews and the sentiment dataset to assign the average objectivity and positive vs. negative scores.\n",
    "\n",
    "If a word cannot be found in the dataset we can ignore it. If a review has no words that match something in our dataset, will can assign overall neutral scores of `objectivity = 1` and `pos_vs_neg = 0`.\n",
    "\n",
    "There are definitely problems with this approach, but for now we can keep it \"dumb\" and see if things improve when we use the VADER analyzer later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='print-most'></a>\n",
    "## Print out the most positive and most negative reviews\n",
    "---\n",
    "\n",
    "Now that we have the average valence for reviews, try printing out the top 10 most positive and top 10 most negative reviews to visually verify that our approach makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='print-most-obj'></a>\n",
    "\n",
    "## Print out the most objective and most subjective reviews\n",
    "---\n",
    "\n",
    "Do the same as above, but now sort by the objectivity. What kind of differences do you notice between these? Does our approach actually appear to capture meaningful subjectivity and objectivity in the reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model'></a>\n",
    "\n",
    "## Build a model to classify fresh vs. rotten with the sentiment and grammar features\n",
    "\n",
    "---\n",
    "\n",
    "Let's use the features we've created to construct a Logistic Regression to predict whether a review is fresh vs. rotten. \n",
    "\n",
    "Don't forget to check the baseline score, and it's a good practice to standardize your predictors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='vader'></a>\n",
    "\n",
    "## Use the VADER library to get better sentiment scores\n",
    "---\n",
    "\n",
    "The [VADER](https://github.com/cjhutto/vaderSentiment) package for python is a more advanced way to calculate positivity, negativity, and objectivity in our reviews. The github page describes VADER as:\n",
    "\n",
    "> VADER Sentiment Analysis. VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media, and works well on texts from other domains.\n",
    "\n",
    "You will likely need to install VADER with pip or conda. Instructions can be found on the github page. Once you have it installed you can load the `SentimentIntensityAnalyzer` and parse text.\n",
    "\n",
    "**Parse a couple of quotes with the `SentimentIntensityAnalyzer` and print out the dictionary of scores using `analyzer.polarity_scores`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pip install vaderSentiment\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that these scores look more legitimate. VADER polarity score dictionaries have 4 elements: `neg`, `pos`, `neu` and `compound`. The compound score is a single metric that represents the \"overall\" valence.\n",
    "\n",
    "**Calculate the four scores for each review and save them as features in the dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='vader-model'></a>\n",
    "\n",
    "### Fit a model using the VADER sentiment features\n",
    "\n",
    "Does this model perform better? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='vader-top'></a>\n",
    "\n",
    "### Print out the top most negative, positive, neutral, and subjective features by VADER score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
