{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Gradient Descent: Iteratively Minimizing Loss Functions \n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- Review derivatives and partial derivatives\n",
    "- Review the least squared loss function for regression\n",
    "- Understand how gradient descent minimizes the loss function\n",
    "- Manually code the gradient descent algorithm from scratch for simple linear regression\n",
    "- Learn how the gradient descent code changes for multiple linear regression\n",
    "- Visualize gradient descent optimizing the coefficients of a regression\n",
    "- Understand the pitfalls of gradient descent and observe when it can fail\n",
    "- Understand how stochastic gradient descent is different, and what the benefits are\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Introduction to gradient descent](#intro)\n",
    "- [Review of derivatives](#derivatives)\n",
    "- [Review of the least squares loss function for regression](#lsq-loss)\n",
    "    - [Exercise 1: code the loss function](#exercise-1)\n",
    "- [Partial derivatives of the loss function](#partial-derivatives)\n",
    "    - [Partial derivative with respect to $\\beta_0$](#beta0)\n",
    "    - [Partial derivative with respect to $\\beta_1$](#beta1)\n",
    "    - [Exercise 2: code the partial derivative functions](#exercise-2)\n",
    "    - [Iterating towards the minimum](#iterating)\n",
    "- [Coding the gradient descent algorithm for SLR](#code-descent-slr)\n",
    "    - [Exercise 3: code the beta coefficient update](#exercise-3)\n",
    "    - [Exercise 4: code the gradient descent iterator](#exercise-4)\n",
    "- [Exercise 5: test the gradient descent algorithm on the simple housing data](#exercise-5)\n",
    "- [Linear algebra MLR generalization of gradient descent](#linalg)\n",
    "- [Interactive visualization of gradient descent](#interactive)\n",
    "- [Gradient descent can fail: a toy example](#fail)\n",
    "- [Stochastic gradient descent](#stochastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "\n",
    "## Introduction to gradient descent\n",
    "\n",
    "---\n",
    "\n",
    "Gradient descent is an algorithm used to minimize functions such as the least-squares loss in regression. It is a very popular in machine learning and statistics.\n",
    "\n",
    "The gradient descent algorithim uses the derivative of the loss function to move in the direction where the loss function is \"descending\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='derivatives'></a>\n",
    "## Derivatives\n",
    "---\n",
    "\n",
    "The derivative of a function quantifies the **rate of change** of the the function with respect to another quantity. \n",
    "\n",
    "Imagine the derivative as a tangent line on the edge of another function. For example, in the image below, if the black curve was the velocity of a car, the red tangent would represent the derivative of velocity at that point: the acceleration of the car.\n",
    "\n",
    "![derivative](https://camo.githubusercontent.com/2f70b084174b825e3ad88564301f9aaf46997fd3/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f302f30662f54616e67656e745f746f5f615f63757276652e737667)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The value of the derivative of a function indicates whether the function is **increasing or decreasing** at that point/input value. \n",
    "\n",
    "* If the function is not changing (the tangent line is flat), **the derivative is 0**\n",
    "* If the function is increasing (the tangent slope is positive), **the derivative is positive**\n",
    "* If the function is decreasing (the tangent slope is negative), **the derivative is negative**\n",
    "\n",
    "**In the case of convex loss functions like the least squared loss, the point where the derivative is 0 is the minimum.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='lsq-loss'></a>\n",
    "\n",
    "## Review: the least squares loss function for regression\n",
    "\n",
    "---\n",
    "\n",
    "Recall the least squares loss function:\n",
    "\n",
    "### $$\\frac{1}{N}\\sum_{i=1}^N{\\left(y_i - \\hat{y}_i\\right)^2}$$\n",
    "\n",
    "As well as the formula for a linear regression with a single predictor variable:\n",
    "\n",
    "### $$y = \\beta_0 + \\beta_1x_1$$\n",
    "\n",
    "We can redefine the loss function, inserting the regression formula:\n",
    "\n",
    "### $$\\frac{1}{N}\\sum_{i=1}^N{\\left(y_i - (\\beta_0 + \\beta_1x_i)\\right)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<a id='exercise-1'></a>\n",
    "### Exercise 1: code the loss function\n",
    "\n",
    "Write a python function for the least squares loss of this simple linear regression in terms of:\n",
    "- `y`: vector of y values\n",
    "- `beta_0`: intercept coefficient\n",
    "- `beta_1`: coefficient for predictor `x`\n",
    "- `x`: vector of predictor values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='partial-derivatives'></a>\n",
    "## Partial derivatives of the loss function\n",
    "\n",
    "---\n",
    "\n",
    "We are going to calculate the two partial derivatives of the loss function. Partial derivatives are derivatives with respect to one variable while holding the other variables constant. Our partial derivatives will be:\n",
    "\n",
    "* The derivative of the loss function with respect to beta0 (the intercept)\n",
    "* The derivative of the loss function with respect to beta1 (the slope/coefficient for x1)\n",
    "\n",
    "This is because the loss function is defined by these two parameters. In other words, the value of the loss function depends on the changes in beta0 and beta1. \n",
    "\n",
    "What about x and y? Those variables affect the calculation of the loss, but we are not able to change them to adjust the error. We can only adjust the parameters of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='beta0'></a>\n",
    "### The partial derivative with respect to $\\beta_0$:\n",
    "\n",
    "### $$\\frac{\\delta}{\\delta\\beta_0} = \\frac{2}{N}\\sum_{i=1}^N{-\\left(y_i - (\\beta_0 + \\beta_1x_1)\\right)}$$\n",
    "\n",
    "<a id='beta1'></a>\n",
    "### The partial derivative with respect to $\\beta_1$:\n",
    "\n",
    "### $$\\frac{\\delta}{\\delta\\beta_1} = \\frac{2}{N}\\sum_{i=1}^N{-x_i\\left(y_i - (\\beta_0 + \\beta_1x_1)\\right)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exercise-2'></a>\n",
    "### Exercise 2: code the partial derivative functions\n",
    "\n",
    "The functions should return the gradients (partial derivatives) of `beta0` and `beta1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "\n",
    "<a id='iterating'></a>\n",
    "### Iterating towards the minimum\n",
    "\n",
    "So what are we going to do with these partial derivatives?\n",
    "\n",
    "Recall that a positive derivative indicates an increasing function and a negative derivative indicates a decreasing function. \n",
    "\n",
    "If we were to subtract a tiny fraction of the partial derivative of $\\beta_1$ from $\\beta_1$, and subtract a tiny fraction of the partial derivative of $\\beta_0$ from $\\beta_0$, we will adjust the beta coefficients such that the value of the loss function shrinks!\n",
    "\n",
    "We can repeat this incremental process until we reach the minimum of the function (or at least, close to the minimum).\n",
    "\n",
    "This is called gradient descent because **we are iteratively moving down the gradient of the error function to its minimum.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/7/79/Gradient_descent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='code-descent'></a>\n",
    "## Coding the gradient descent algorithm for SLR\n",
    "\n",
    "---\n",
    "\n",
    "We will now code the gradient descent algorithm to find the optimal intercept and slope for a simple linear regression using the least squares loss function.\n",
    "\n",
    "We have already coded a few of the components into functions:\n",
    "- **The mean squared error**\n",
    "- **The beta_0 gradient (partial derivative)**\n",
    "- **The beta_1 gradient (partial derivative)**\n",
    "\n",
    "Now we are going to code two more functions:\n",
    "- **The beta coefficient update function**\n",
    "- **The gradient descent iteration function**\n",
    "\n",
    "<a id='exercise-3'></a>\n",
    "### Exercise 3: code the beta coefficient update function\n",
    "\n",
    "The beta coefficient update function iterates through every observed `y` and predictor `x`. It will calculate the changes to the current `beta0` and `beta1` values to move the loss function (mean squared error) closer to its minimum.\n",
    "\n",
    "The update function will take these arguments:\n",
    "- `y`: vector of observed target values\n",
    "- `x`: vector of predictor values\n",
    "- `beta0`: current value of the intercept\n",
    "- `beta1`: current value of the coefficient for `x`\n",
    "- `step_size`: a step size to multiply the gradients by\n",
    "\n",
    "The **step size** controls how much the gradient update should modify the coefficients. It is good to take very small steps towards the minimum so that the algorithm doesn't overshoot and spin out of control.\n",
    "\n",
    "**Your function should return the new values of `beta0` and `beta1`.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exercise-4'></a>\n",
    "### Exercise 4: code the gradient descent iterator\n",
    "\n",
    "Last we can put it all together by coding a function that will iterate down the gradient of the loss function towards the minimum. At each step the function will call the gradient update function.\n",
    "\n",
    "We should keep track of the beta coefficients and the mean squared error in lists as the algorithm progresses.\n",
    "\n",
    "**The arguments to the function will be:**\n",
    "- `x`: the vector of predictors\n",
    "- `y`: the vector of observed target values\n",
    "- `beta0`: an initial value for the intercept\n",
    "- `beta1`: an initial value for the slope\n",
    "- `step_size`: a step size for the gradient update\n",
    "- `iterations`: how many times the gradient update function should be called before stopping\n",
    "\n",
    "> **Note:** make sure your step size is quite small (`0.0000001`, for example) or the MSE will increase because the step size is too large!\n",
    "\n",
    "At each iteration, keep track of the current `beta0`, `beta1` and the mean squared error.\n",
    "\n",
    "**The function should return the lists of `beta0`, `beta1`, and `mse` values for the iterations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exercise-5'></a>\n",
    "\n",
    "## Exercise 5: Test your gradient descent code on the simple housing dataset\n",
    "\n",
    "---\n",
    "\n",
    "Load in the simple housing data. Set up two variables:\n",
    "- `y`: the price of the house divided by 1000.\n",
    "- `x`: the sqft of the house\n",
    "\n",
    "Initialize starting values for `beta0` and `beta1`. Then run your gradient descent iterator, returning the array of MSEs and coefficients at each step. \n",
    "\n",
    "Finally, plot the trajectory of the MSEs, beta0s, and beta1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house = pd.read_csv('./datasets/housing-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='linalg'></a>\n",
    "\n",
    "## Linear algebra MLR generalization of the gradient descent code\n",
    "\n",
    "---\n",
    "\n",
    "Now that we have coded the gradient descent for a simple linear regression, we can generalize this code to work for a matrix of predictors instead of just one predictor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### New mean squared error loss function\n",
    "\n",
    "This function calculates the mean of the squared errors using a dot product between the `X` predictor matrix and the `beta_array`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# def mean_squared_error(X, y, beta_array):\n",
    "#     y_hat = np.dot(X, beta_array)\n",
    "#     mean_sq_err = np.mean((y_true - y_hat)**2)\n",
    "#     return mean_sq_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### New $\\beta$ update function\n",
    "\n",
    "This will update the value of $\\beta_array$. We still use the partial derivitave formulas above, with some linear algebra tweaks to make it work with an arbitary $X$ predictor matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def beta_update_function(X, y, beta_array, step_size):\n",
    "#     # create a transposed version of the X predictor array:\n",
    "#     Xt = X.T\n",
    "    \n",
    "#     # predictions are the dot product of the X matrix and the beta matrix:\n",
    "#     y_hat = np.dot(X, beta_array)\n",
    "    \n",
    "#     # residuals are the true y minus the predicted y\n",
    "#     residuals = y_hat - y\n",
    "    \n",
    "#     # calculate the gradient from the partial derivatives.\n",
    "#     # this works out to actually do both at the same time.\n",
    "#     # How? Well, because the beta0 column is all 1s, the \n",
    "#     # dot product turns out to be the same as the beta0\n",
    "#     # partial derivative function!\n",
    "#     gradient = np.dot(Xt, residuals) / (X.shape[0]/2.)\n",
    "    \n",
    "#     # update the betas with the gradient:\n",
    "#     beta_array = beta_array - (step_size * gradient)\n",
    "    \n",
    "#     return beta_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### New gradient descent iteration update function\n",
    "\n",
    "This is the function that wraps the gradient update with some number of iterations. It is the same, but takes an array of beta coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# def run_gradient_descent(X, y, initial_beta_array, step_size, iterations=500):\n",
    "    \n",
    "#     beta_array = initial_beta_array\n",
    "    \n",
    "#     # Set up the MSE tracker\n",
    "#     mses = []\n",
    "#     mses.append(mean_squared_error(X, y, beta_array))\n",
    "    \n",
    "#     # track the betas over the iterations:\n",
    "#     beta_arrays = []\n",
    "\n",
    "#     # update the betas via gradient descent:\n",
    "#     for i in range(iterations):\n",
    "#         beta_array = beta_update_function(X, y, beta_array, step_size)\n",
    "#         mses.append(mean_squared_error(X, y, beta_array))\n",
    "#         beta_arrays.append(beta_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='interactive'></a>\n",
    "\n",
    "## Interactive visualization of gradient descent\n",
    "\n",
    "This interactive visualization lets you watch gradient descent solve the optimal coefficient values.\n",
    "\n",
    "> **Note:** Because this is a very simple implementation, there is no automatic adjustment of step size, so setting this value can be finnicky and you sort of have to play around with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# import imp\n",
    "# plotter = imp.load_source('plotter', './code/gradient_descent.py')\n",
    "# from plotter import GradientDescentPlotter\n",
    "\n",
    "# gd_plotter = GradientDescentPlotter(step_size=0.001)\n",
    "# gd_plotter.run_gradient_descent(iterations=5000)\n",
    "# gd_plotter.gradient_interact()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='fail'></a>\n",
    "\n",
    "## Gradient descent can fail: a toy example\n",
    "\n",
    "---\n",
    "\n",
    "One of the most delicate things about gradient descent is the step size (also known as learning rate). If this is not tuned properly, the algorithm may never converge and in fact explode into extreme values.\n",
    "\n",
    "But that is not the only pitfall with gradient descent: it can also get stuck in \"local minima\" and only works where there is a gradient to follow. \n",
    "\n",
    "Here is a toy example of a function where gradient descent will fail:\n",
    "\n",
    "$$f(x, y) = \\begin{cases}\n",
    "2 x^2 & \\quad \\text{if $x \\leq 1$}\\\\\n",
    "2  & \\quad \\text{else}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# def func(x):\n",
    "#     if x <= 1:\n",
    "#         return 2 * x * x\n",
    "#     return 2\n",
    "\n",
    "# def gradient(x):\n",
    "#     if x <= 1:\n",
    "#         return 4 * x\n",
    "#     return 0\n",
    "\n",
    "# def gradient_descent(x, l=0.1):\n",
    "#     vector = np.array(x)\n",
    "#     return vector - l * np.array(gradient(x))\n",
    "\n",
    "\n",
    "# def iterate(x0, n=10):\n",
    "#     xs = [x0]\n",
    "#     ys = [func(x0)]\n",
    "#     for i in range(n):\n",
    "#         x = gradient_descent(xs[-1], l=0.1)\n",
    "#         xs.append(x)\n",
    "#         ys.append(func(x))\n",
    "#     return xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Run the gradient descent algorithm starting at `x = -1.5` first, then try it at `x = 2`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# xs = np.arange(-2, 3, 0.1)\n",
    "# ys = map(func, xs)\n",
    "\n",
    "# plt.figure(figsize=(10,8))\n",
    "# plt.plot(xs, ys, alpha=0.5, ls='dashed')\n",
    "\n",
    "# # Start gradient descent at x = -1.5\n",
    "# xs2, ys2 = iterate(-1.5, n=10)\n",
    "# plt.scatter(xs2, ys2, c='r', s=100)\n",
    "\n",
    "# # Start gradient descent at x = 2\n",
    "# xs2, ys2 = iterate(2, n=10)\n",
    "# plt.scatter(xs2, ys2, c='y', s=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='stochastic'></a>\n",
    "## Stochastic Gradient Descent\n",
    "\n",
    "---\n",
    "\n",
    "What is the difference between gradient descent and *stochastic* gradient descent? It's actually a very small difference, but has big implications.\n",
    "\n",
    "Instead of **all** the samples updating the gradient at a time, **only one** sample updates the gradient (iterating over all the observations, though this can change based on specification) within each overall iteration.\n",
    "\n",
    "**Stochastic gradient descent has some nice properties over gradient descent:**\n",
    "- It solves faster since it immediately starts to update the gradient.\n",
    "- It can handle much, much larger datasets since it only needs to calculate a single row or small batch of rows of the entire dataset.\n",
    "\n",
    "When using sklearn, there are only implementations of stochastic gradient descent solvers: `SGDRegressor` and `SGDClassifier`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
