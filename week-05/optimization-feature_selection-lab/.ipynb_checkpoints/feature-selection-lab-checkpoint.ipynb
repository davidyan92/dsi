{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Feature Selection on the Titanic Dataset\n",
    "\n",
    "_Authors: Joseph Nelson (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "In this lab you will explore a variety of different feature selection methods in sklearn. You will be using the titanic dataset.\n",
    "\n",
    "You can load the titanic data as follows:\n",
    "\n",
    "    psql -h dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com -p 5432 -U dsi_student titanic\n",
    "    password: gastudents\n",
    "\n",
    "Or alternatively load the dataset from the local folder:\n",
    "\n",
    "    ./datasets/titanic_train.csv\n",
    "    \n",
    "\n",
    "## Some useful feature selection resources\n",
    "\n",
    "---\n",
    "\n",
    "- Michigan State Overview on [feature selection](http://www.cse.msu.edu/~cse802/Feature_selection.pdf) and (bonus) Texas A&M on [bidrectional feature selection](http://research.cs.tamu.edu/prism/lectures/pr/pr_l11.pdf)\n",
    "- Sklearn documentation on [feature selection](http://scikit-learn.org/stable/modules/feature_selection.html)\n",
    "- Side-by-side comparison of [feature selection tactics](http://blog.datadive.net/selecting-good-features-part-iv-stability-selection-rfe-and-everything-side-by-side/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1. Import the data and perform EDA. Engineer any features you think are predictive of survival.\n",
    "\n",
    "We'll be working with the titanic datasets - go ahead and import it from the dataset folder (or query for it as described above). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/titanic_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set up predictor and target matrices\n",
    "\n",
    "- target should be `Survived`\n",
    "- predictor matrix will be all other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature selection\n",
    "\n",
    "Let's use the `SelectKBest` method in scikit learn to see which are the top 5 features. Also load the `f_classif` and `chi2` functions which will be our metrics to evaluate what makes a variable the \"best\".\n",
    "\n",
    "```python\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "```\n",
    "\n",
    "- What are the top 5 features for `X` using `f_classif`?\n",
    "- What are the top 5 features for `X` using `chi2`?\n",
    "\n",
    "\n",
    "> The f-test is explained variance divided by unexplained variance. High numbers will results if our explained variance, what we know is much greater than unexplained, what we dont know. The Chi2 goodness of fit is the sum of the difference squared between observed and expected divided by expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "\n",
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Recursive Feature Elimination (RFE)\n",
    "\n",
    "Sklearn also offers recursive feature elimination as a class named `RFECV`. Use it in combination with a logistic regression model to see what features would be kept with this method.\n",
    "\n",
    "When instantiating the `RFECV`:\n",
    "- `step` indicates what percent of features (or number of features if an integer) to remove at each iteration.\n",
    "- `cv` indicates the number of cross-validation folds to use for evaluating what features are important.\n",
    "\n",
    "Store the columns in a variable called `rfecv_columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Feature elimination using the lasso penalty\n",
    "\n",
    "The L1 penalty is a popular method for feature selection. As the regularization strength increases more features will be removed.\n",
    "\n",
    "Load the `LogisticRegressionCV` class.\n",
    "\n",
    "1. Standardize your predictor matrix (required for regularization!)\n",
    "- Create a logistic regression cross-validator object :\n",
    "    - Set `penalty='l1'` (Lasso).\n",
    "    - Set `Cs=100` (search 100 different regularization strengths).\n",
    "    - Set `solver='liblinear'` (required for the Lasso penalty).\n",
    "    - Set `cv=10` for 10 cross-validation folds.\n",
    "- Fit on the target and standardized predictors.\n",
    "- Sort the logistic regression coefficients by absolute value. Do the top 5 correspond to those selected by the f-score and chi2?\n",
    "\n",
    "\n",
    "\n",
    "Choose which ones you would keep and store them in a variable called `lr_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Compare features sets\n",
    "\n",
    "Use the optimized logistic regression from the previous question on the features selected from different methods. \n",
    "- `kbest_columns`\n",
    "- `rfecv_columns`\n",
    "- `lasso_columns`\n",
    "- `all_columns`\n",
    "\n",
    "**Questions:**\n",
    "- Which scores the highest? (use cross_val_score)\n",
    "- Is the difference significant?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. [Bonus] Display the lasso logistic regression coefficients with a barchart.\n",
    "\n",
    "Start from the most negative on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
