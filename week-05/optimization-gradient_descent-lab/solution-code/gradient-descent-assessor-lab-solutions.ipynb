{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Gradient Descent in Sklearn\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "Until now we've been using specific sklearn model classes to perform regression and classification such as `LinearRegression` and `LogisticRegression`. Unfortunately, while these methods work well on smaller datasets with relatively small numbers of columns, once you start getting into \"Medium Data\" these slow down to a crawl, and take up so much memory that fitting them becomes mind-numbingly slow (especially on a laptop).\n",
    "\n",
    "Luckily, sklearn comes with  stochastic gradient descent solvers for regression and classification:\n",
    "- `SGDRegressor`\n",
    "- `SGDClassifier`\n",
    "\n",
    "Due to its ability to minimize the loss function iteratively on smaller portions of the data, it avoids the intense slowdown other models suffer on large datasets.\n",
    "\n",
    "> **Note:** The gradient descent solvers are very flexible and can fit a variety of different model types not covered here. I highly recommend reading their documentation in detail.\n",
    "\n",
    "---\n",
    "\n",
    "### SF assessor data\n",
    "\n",
    "This lab uses data from the SF assessor's office on housing prices in San Francisco - it's already cleaned up.\n",
    "\n",
    "You can see that the dataset has 250k rows. When expanding this with dummy-coded categorical columns it can become quite large. Be careful that you don't exceed the memory on your computer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "import patsy\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data.\n",
    "\n",
    "Examine the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prop = pd.read_csv('../datasets/assessor_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baths               int64\n",
       "beds                int64\n",
       "lot_depth         float64\n",
       "basement_area     float64\n",
       "front_ft          float64\n",
       "owner_pct         float64\n",
       "rooms               int64\n",
       "property_class     object\n",
       "neighborhood       object\n",
       "tax_rate          float64\n",
       "volume              int64\n",
       "sqft                int64\n",
       "stories             int64\n",
       "year_recorded       int64\n",
       "year_built          int64\n",
       "zone               object\n",
       "value             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baths             0\n",
       "beds              0\n",
       "lot_depth         0\n",
       "basement_area     0\n",
       "front_ft          0\n",
       "owner_pct         0\n",
       "rooms             0\n",
       "property_class    0\n",
       "neighborhood      0\n",
       "tax_rate          0\n",
       "volume            0\n",
       "sqft              0\n",
       "stories           0\n",
       "year_recorded     0\n",
       "year_built        0\n",
       "zone              0\n",
       "value             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['D', 'Z', 'DBM', 'LZ', 'TH', 'ZBM'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop.property_class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01E', '10G', '10C', '02C', '02A', '04S', '08F', '10H', '03A',\n",
       "       '02F', '10B', '04T', '04J', '04M', '08E', '10F', '10E', '03G',\n",
       "       '03H', '06D', '09E', '02B', '02D', '10D', '01C', '07B', '02E',\n",
       "       '04C', '04H', '10A', '05A', '04F', '04E', '10J', '09A', '03B',\n",
       "       '07C', '01A', '01G', '09G', '02G', '05C', '05F', '03J', '05K',\n",
       "       '03E', '06A', '05D', '08C', '04G', '04R', '06B', '01D', '07A',\n",
       "       '09C', '09F', '10K', '01F', '05G', '03C', '09H', '04B', '08G',\n",
       "       '04N', '05B', '08A', '08H', '04P', '03F', '07D', '06E', '01B',\n",
       "       '05M', '05E', '06C', '04D', '05H', '08B', '05J', '09D', '04A',\n",
       "       '04K', '08D', '06F', '03D', '09B', '047', '08I'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop.neighborhood.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sample down the data\n",
    "\n",
    "Despite this already being a sample of the full assessor dataset, you should sample the data down further the sake of speed and your computers memory.\n",
    "\n",
    "Use the `.sample()` function for pandas dataframes to subset this down to < 25000 rows. \n",
    "\n",
    "Sampling down large datasets is a common procedure. Finding the optimal parameters with larger subsets of the data may change the hyperparameters and the results, and will get you closer to the best coefficients, but the returns are marginal at a point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_samp = prop.sample(n=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Regression with stochastic gradient descent\n",
    "\n",
    "Below I set up X, y data predicting value (housing price) from the remaining variables. There are ~75,000 rows, with 170 columns.\n",
    "\n",
    "\n",
    "The `SGDRegressor` is very general and flexible, and can be customized with a variety of keyword arguments.\n",
    "\n",
    "**Arguments**\n",
    "- `loss`: `['squared_loss','huber', ...]`\n",
    "    - The `'squared_loss'` loss corresponds to solving a regression with the least squares loss. This is what I expect you'll use, but there are other options. Huber loss is a \"robust\" regression loss.\n",
    "- `penalty`: `['none','l1','l2','elasticnet']`\n",
    "    - This defines the penalty on the regression that you would like to solve. The l1 and l2 are the Lasso and Ridge, while the elasticnet is the combination of them both.\n",
    "- `alpha`\n",
    "    - The regularization strength to be used with a chosen penalty. Same as in Lasso and Ridge.\n",
    "- `l1_ratio`\n",
    "    - The mix of the Lasso and Ridge penalties when elasticnet is chosen as the penalty.\n",
    "- `n_iter`\n",
    "    - The number of training \"epochs\" over the data. This is the number of passes that the gradient descent algorithm will make over the data to iteratively fit the weights (defaults to 5).\n",
    "\n",
    "`SGDRegressor` is most often used in tandem with grid searching to find the optimal parameters for certain models. \n",
    "\n",
    "**It is up to you how you want to define the model. You should:**\n",
    "\n",
    "1. Choose a target to estimate (this should be continuous).\n",
    "- Select predictors to use.\n",
    "- Standardize your predictor matrix.\n",
    "- Build a stochastic gradient descent solver to fit your model. You will likely want to do some kind of gridsearch to find the optimal parameters for your model.\n",
    "- Describe the model selected through gridsearch and compare the performance to baseline.\n",
    "- Examine and interpret the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value ~ baths + beds + lot_depth + basement_area + front_ft + owner_pct + rooms + property_class + neighborhood + tax_rate + volume + sqft + stories + year_recorded + year_built + zone -1\n",
      "(25000,) (25000, 163)\n"
     ]
    }
   ],
   "source": [
    "f = 'value ~ '+' + '.join([c for c in prop_samp.columns if not c == 'value'])+' -1'\n",
    "print f\n",
    "y, X = patsy.dmatrices(f, data=prop_samp, return_type='dataframe')\n",
    "y = y.values.ravel()\n",
    "\n",
    "print y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I am predicting the value of the house from the other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor, SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 163)\n"
     ]
    }
   ],
   "source": [
    "# standardize the predictors\n",
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)\n",
    "print Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up my gridsearch parameters:\n",
    "sgd_params = {\n",
    "    'loss':['squared_loss','huber'],\n",
    "    'penalty':['l1','l2'],\n",
    "    'alpha':np.logspace(-5,1,25)\n",
    "}\n",
    "\n",
    "sgd_reg = SGDRegressor()\n",
    "sgd_reg_gs = GridSearchCV(sgd_reg, sgd_params, cv=5, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', n_iter=5, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'loss': ['squared_loss', 'huber'], 'alpha': array([  1.00000e-05,   1.77828e-05,   3.16228e-05,   5.62341e-05,\n",
       "         1.00000e-04,   1.77828e-04,   3.16228e-04,   5.62341e-04,\n",
       "         1.00000e-03,   1.77828e-03,   3.16228e-03,   5.62341e-03,\n",
       "         1.00000e-...2341e-01,\n",
       "         1.00000e+00,   1.77828e+00,   3.16228e+00,   5.62341e+00,\n",
       "         1.00000e+01])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SGD is pretty fast compared to other sklearn solvers - but can still\n",
    "# take a good long while depending on the gridsearch and the size of\n",
    "# the dataset.\n",
    "sgd_reg_gs.fit(Xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2', 'alpha': 1.0, 'loss': 'squared_loss'}\n",
      "0.197097050112\n"
     ]
    }
   ],
   "source": [
    "print sgd_reg_gs.best_params_\n",
    "print sgd_reg_gs.best_score_\n",
    "sgd_reg = sgd_reg_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can see that the gradient descent got a .22 R2 using the ridge and squared loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>mag</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>30973.212863</td>\n",
       "      <td>30973.212863</td>\n",
       "      <td>zone[T.SACTO]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>26780.222137</td>\n",
       "      <td>26780.222137</td>\n",
       "      <td>beds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>23451.630577</td>\n",
       "      <td>23451.630577</td>\n",
       "      <td>neighborhood[T.05C]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>21676.077188</td>\n",
       "      <td>21676.077188</td>\n",
       "      <td>sqft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-18560.858293</td>\n",
       "      <td>18560.858293</td>\n",
       "      <td>owner_pct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>17215.526707</td>\n",
       "      <td>17215.526707</td>\n",
       "      <td>neighborhood[T.07A]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>16389.914561</td>\n",
       "      <td>16389.914561</td>\n",
       "      <td>baths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>14847.013586</td>\n",
       "      <td>14847.013586</td>\n",
       "      <td>neighborhood[T.05H]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>14315.475303</td>\n",
       "      <td>14315.475303</td>\n",
       "      <td>zone[T.RH3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-14245.125629</td>\n",
       "      <td>14245.125629</td>\n",
       "      <td>volume</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef           mag                 pred\n",
       "143  30973.212863  30973.212863        zone[T.SACTO]\n",
       "151  26780.222137  26780.222137                 beds\n",
       "47   23451.630577  23451.630577  neighborhood[T.05C]\n",
       "159  21676.077188  21676.077188                 sqft\n",
       "155 -18560.858293  18560.858293            owner_pct\n",
       "62   17215.526707  17215.526707  neighborhood[T.07A]\n",
       "150  16389.914561  16389.914561                baths\n",
       "52   14847.013586  14847.013586  neighborhood[T.05H]\n",
       "127  14315.475303  14315.475303          zone[T.RH3]\n",
       "158 -14245.125629  14245.125629               volume"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_coefs = pd.DataFrame({'coef':sgd_reg.coef_,\n",
    "                            'mag':np.abs(sgd_reg.coef_),\n",
    "                            'pred':X.columns})\n",
    "value_coefs.sort_values('mag', ascending=False, inplace=True)\n",
    "value_coefs.iloc[0:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Classification with stochastic gradient descent\n",
    "\n",
    "The `SGDClassifier` is very similar to the `SGDRegressor`. The main difference is that the loss functions are changed to regression loss functions.\n",
    "\n",
    "**Arguments**\n",
    "- `loss`: `['log', ...]`\n",
    "    - The `'log'` loss corresponds to solving a logistic regression classifier. This is what I expect you'll use, but there are many other options.\n",
    "- `penalty`: `['none','l1','l2','elasticnet']`\n",
    "    - This defines the penalty on the regression that you would like to solve. The l1 and l2 are the Lasso and Ridge, while the elasticnet is the combination of them both.\n",
    "- `alpha`\n",
    "    - The regularization strength to be used with a chosen penalty. Same as in Lasso and Ridge.\n",
    "- `l1_ratio`\n",
    "    - The mix of the Lasso and Ridge penalties when elasticnet is chosen as the penalty.\n",
    "- `n_iter`\n",
    "    - The number of training \"epochs\" over the data. This is the number of passes that the gradient descent algorithm will make over the data to iteratively fit the weights (defaults to 5).\n",
    "\n",
    "Like `SGDRegressor`, `SGDClassifier` is most often used in tandem with grid searching to find the optimal parameters for certain models. \n",
    "\n",
    "**It is up to you how you want to define the model. You should:**\n",
    "\n",
    "1. Choose a target to classify (you may need to engineer one from existing variables).\n",
    "- Calculate the baseline accuracy.\n",
    "- Select predictors to use.\n",
    "- Standardize your predictor matrix.\n",
    "- Build a stochastic gradient descent solver to fit your model. You will likely want to do some kind of gridsearch to find the optimal parameters for your model.\n",
    "- Describe the model selected through gridsearch and compare the performance to baseline.\n",
    "- Examine and interpret the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'baths', u'beds', u'lot_depth', u'basement_area', u'front_ft',\n",
       "       u'owner_pct', u'rooms', u'property_class', u'neighborhood', u'tax_rate',\n",
       "       u'volume', u'sqft', u'stories', u'year_recorded', u'year_built',\n",
       "       u'zone', u'value'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_samp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1941    1015\n",
       "1940     897\n",
       "1925     877\n",
       "1926     776\n",
       "1924     764\n",
       "1927     698\n",
       "1923     693\n",
       "1939     643\n",
       "1947     603\n",
       "1948     514\n",
       "1908     491\n",
       "1928     478\n",
       "1922     467\n",
       "1946     466\n",
       "1906     459\n",
       "1950     437\n",
       "1938     421\n",
       "1907     417\n",
       "1951     411\n",
       "1931     375\n",
       "1944     363\n",
       "1910     349\n",
       "1930     344\n",
       "1936     344\n",
       "1949     342\n",
       "1929     333\n",
       "1937     315\n",
       "1942     313\n",
       "1912     294\n",
       "1955     260\n",
       "        ... \n",
       "1984     114\n",
       "1979     113\n",
       "1993     111\n",
       "1997     107\n",
       "1933     102\n",
       "1995     102\n",
       "1985      92\n",
       "1998      91\n",
       "1918      84\n",
       "1994      82\n",
       "1976      77\n",
       "1973      73\n",
       "1966      67\n",
       "1977      60\n",
       "1970      54\n",
       "1974      54\n",
       "1902      52\n",
       "1903      49\n",
       "1967      46\n",
       "1934      43\n",
       "2000      43\n",
       "1968      42\n",
       "1971      32\n",
       "1969      28\n",
       "1999      20\n",
       "1901      11\n",
       "2001       5\n",
       "2003       3\n",
       "2002       1\n",
       "2005       1\n",
       "Name: year_built, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_samp.year_built.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets see if we can predict if a house was built past 1980\n",
    "prop_samp['built_past1980'] = prop_samp.year_built.map(lambda x: 1 if x >= 1980 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89576\n"
     ]
    }
   ],
   "source": [
    "# make the target and calculate the baseline:\n",
    "y = prop_samp.built_past1980.values\n",
    "print 1. - np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = '''\n",
    "~ baths + beds + lot_depth + basement_area + front_ft + owner_pct +\n",
    "rooms + property_class + neighborhood + tax_rate + volume + sqft + stories +\n",
    "zone + value -1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000, 162)\n"
     ]
    }
   ],
   "source": [
    "X = patsy.dmatrix(f, data=prop_samp, return_type='dataframe')\n",
    "\n",
    "Xs = ss.fit_transform(X)\n",
    "print y.shape, Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd_cls_params = {\n",
    "    'loss':['log'],\n",
    "    'penalty':['l1','l2'],\n",
    "    'alpha':np.logspace(-5,2,50)\n",
    "}\n",
    "\n",
    "sgd_cls = SGDClassifier()\n",
    "sgd_cls_gs = GridSearchCV(sgd_cls, sgd_cls_params, cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   52.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'loss': ['log'], 'alpha': array([  1.00000e-05,   1.38950e-05,   1.93070e-05,   2.68270e-05,\n",
       "         3.72759e-05,   5.17947e-05,   7.19686e-05,   1.00000e-04,\n",
       "         1.38950e-04,   1.93070e-04,   2.68270e-04,   3.72759e-04,\n",
       "         5.17947e-04,   7.19686e-04,...    1.93070e+01,   2.68270e+01,   3.72759e+01,   5.17947e+01,\n",
       "         7.19686e+01,   1.00000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_cls_gs.fit(Xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'alpha': 0.00019306977288832496, 'loss': 'log'}\n",
      "0.96236\n"
     ]
    }
   ],
   "source": [
    "print sgd_cls_gs.best_params_\n",
    "print sgd_cls_gs.best_score_\n",
    "sgd_cls = sgd_cls_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
