{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Gradient Descent in Sklearn\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "Until now we've been using specific sklearn model classes to perform regression and classification such as `LinearRegression` and `LogisticRegression`. Unfortunately, while these methods work well on smaller datasets with relatively small numbers of columns, once you start getting into \"Medium Data\" these slow down to a crawl, and take up so much memory that fitting them becomes mind-numbingly slow (especially on a laptop).\n",
    "\n",
    "Luckily, sklearn comes with  stochastic gradient descent solvers for regression and classification:\n",
    "- `SGDRegressor`\n",
    "- `SGDClassifier`\n",
    "\n",
    "Due to its ability to minimize the loss function iteratively on smaller portions of the data, it avoids the intense slowdown other models suffer on large datasets.\n",
    "\n",
    "> **Note:** The gradient descent solvers are very flexible and can fit a variety of different model types not covered here. I highly recommend reading their documentation in detail.\n",
    "\n",
    "---\n",
    "\n",
    "### SF assessor data\n",
    "\n",
    "This lab uses data from the SF assessor's office on housing prices in San Francisco - it's already cleaned up.\n",
    "\n",
    "You can see that the dataset has 250k rows. When expanding this with dummy-coded categorical columns it can become quite large. Be careful that you don't exceed the memory on your computer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "import patsy\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data.\n",
    "\n",
    "Examine the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop = pd.read_csv('./datasets/assessor_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 17)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A:\n",
    "prop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250000 entries, 0 to 249999\n",
      "Data columns (total 17 columns):\n",
      "baths             250000 non-null int64\n",
      "beds              250000 non-null int64\n",
      "lot_depth         250000 non-null float64\n",
      "basement_area     250000 non-null float64\n",
      "front_ft          250000 non-null float64\n",
      "owner_pct         250000 non-null float64\n",
      "rooms             250000 non-null int64\n",
      "property_class    250000 non-null object\n",
      "neighborhood      250000 non-null object\n",
      "tax_rate          250000 non-null float64\n",
      "volume            250000 non-null int64\n",
      "sqft              250000 non-null int64\n",
      "stories           250000 non-null int64\n",
      "year_recorded     250000 non-null int64\n",
      "year_built        250000 non-null int64\n",
      "zone              250000 non-null object\n",
      "value             250000 non-null float64\n",
      "dtypes: float64(6), int64(8), object(3)\n",
      "memory usage: 32.4+ MB\n"
     ]
    }
   ],
   "source": [
    "prop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sample down the data\n",
    "\n",
    "Despite this already being a sample of the full assessor dataset, you should sample the data down further the sake of speed and your computers memory.\n",
    "\n",
    "Use the `.sample()` function for pandas dataframes to subset this down to < 25000 rows. \n",
    "\n",
    "Sampling down large datasets is a common procedure. Finding the optimal parameters with larger subsets of the data may change the hyperparameters and the results, and will get you closer to the best coefficients, but the returns are marginal at a point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_samp = prop.sample(n=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Regression with stochastic gradient descent\n",
    "\n",
    "Below I set up X, y data predicting value (housing price) from the remaining variables. There are ~75,000 rows, with 170 columns.\n",
    "\n",
    "\n",
    "The `SGDRegressor` is very general and flexible, and can be customized with a variety of keyword arguments.\n",
    "\n",
    "**Arguments**\n",
    "- `loss`: `['squared_loss','huber', ...]`\n",
    "    - The `'squared_loss'` loss corresponds to solving a regression with the least squares loss. This is what I expect you'll use, but there are other options. Huber loss is a \"robust\" regression loss.\n",
    "- `penalty`: `['none','l1','l2','elasticnet']`\n",
    "    - This defines the penalty on the regression that you would like to solve. The l1 and l2 are the Lasso and Ridge, while the elasticnet is the combination of them both.\n",
    "- `alpha`\n",
    "    - The regularization strength to be used with a chosen penalty. Same as in Lasso and Ridge.\n",
    "- `l1_ratio`\n",
    "    - The mix of the Lasso and Ridge penalties when elasticnet is chosen as the penalty.\n",
    "- `n_iter`\n",
    "    - The number of training \"epochs\" over the data. This is the number of passes that the gradient descent algorithm will make over the data to iteratively fit the weights (defaults to 5).\n",
    "\n",
    "`SGDRegressor` is most often used in tandem with grid searching to find the optimal parameters for certain models. \n",
    "\n",
    "**It is up to you how you want to define the model. You should:**\n",
    "\n",
    "1. Choose a target to estimate (this should be continuous).\n",
    "- Select predictors to use.\n",
    "- Standardize your predictor matrix.\n",
    "- Build a stochastic gradient descent solver to fit your model. You will likely want to do some kind of gridsearch to find the optimal parameters for your model.\n",
    "- Describe the model selected through gridsearch and compare the performance to baseline.\n",
    "- Examine and interpret the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value ~ baths + beds + lot_depth + basement_area + front_ft + owner_pct + rooms + property_class + neighborhood + tax_rate + volume + sqft + stories + year_recorded + year_built + zone\n",
      "(25000,) (25000, 163)\n"
     ]
    }
   ],
   "source": [
    "f = 'value ~ ' + ' + '.join([c for c in prop_samp.columns if not c == 'value'])\n",
    "print f\n",
    "\n",
    "y, X = patsy.dmatrices(f, data=prop_samp, return_type='dataframe')\n",
    "y = y.values.ravel()\n",
    "\n",
    "print y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor, SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_params = {\n",
    "    'loss':['squared_loss','huber'],\n",
    "    'penalty':['l1','l2'],\n",
    "    'alpha':np.logspace(-5,1,25)\n",
    "}\n",
    "\n",
    "sgd_reg = SGDRegressor()\n",
    "sgd_reg_gs = GridSearchCV(sgd_reg, sgd_params, cv=5, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', max_iter=None, n_iter=None, penalty='l2',\n",
       "       power_t=0.25, random_state=None, shuffle=True, tol=None, verbose=0,\n",
       "       warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'loss': ['squared_loss', 'huber'], 'alpha': array([  1.00000e-05,   1.77828e-05,   3.16228e-05,   5.62341e-05,\n",
       "         1.00000e-04,   1.77828e-04,   3.16228e-04,   5.62341e-04,\n",
       "         1.00000e-03,   1.77828e-03,   3.16228e-03,   5.62341e-03,\n",
       "         1.00000e-...2341e-01,\n",
       "         1.00000e+00,   1.77828e+00,   3.16228e+00,   5.62341e+00,\n",
       "         1.00000e+01])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_reg_gs.fit(Xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2', 'alpha': 1.0, 'loss': 'squared_loss'}\n",
      "0.202694718146\n"
     ]
    }
   ],
   "source": [
    "print(sgd_reg_gs.best_params_)\n",
    "print(sgd_reg_gs.best_score_)\n",
    "# get the best model\n",
    "sgd_reg = sgd_reg_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>mag</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>28330.631430</td>\n",
       "      <td>28330.631430</td>\n",
       "      <td>beds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>28300.755719</td>\n",
       "      <td>28300.755719</td>\n",
       "      <td>sqft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>27200.744223</td>\n",
       "      <td>27200.744223</td>\n",
       "      <td>zone[T.RH1S]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>26712.685032</td>\n",
       "      <td>26712.685032</td>\n",
       "      <td>neighborhood[T.07B]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>21218.939825</td>\n",
       "      <td>21218.939825</td>\n",
       "      <td>neighborhood[T.08E]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19891.479713</td>\n",
       "      <td>19891.479713</td>\n",
       "      <td>neighborhood[T.01F]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>19213.867708</td>\n",
       "      <td>19213.867708</td>\n",
       "      <td>neighborhood[T.05K]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18173.063253</td>\n",
       "      <td>18173.063253</td>\n",
       "      <td>property_class[T.Z]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-17663.037711</td>\n",
       "      <td>17663.037711</td>\n",
       "      <td>volume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>17649.710185</td>\n",
       "      <td>17649.710185</td>\n",
       "      <td>zone[T.RHZ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef           mag                 pred\n",
       "151  28330.631430  28330.631430                 beds\n",
       "159  28300.755719  28300.755719                 sqft\n",
       "123  27200.744223  27200.744223         zone[T.RH1S]\n",
       "63   26712.685032  26712.685032  neighborhood[T.07B]\n",
       "70   21218.939825  21218.939825  neighborhood[T.08E]\n",
       "10   19891.479713  19891.479713  neighborhood[T.01F]\n",
       "54   19213.867708  19213.867708  neighborhood[T.05K]\n",
       "4    18173.063253  18173.063253  property_class[T.Z]\n",
       "158 -17663.037711  17663.037711               volume\n",
       "129  17649.710185  17649.710185          zone[T.RHZ]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_coefs = pd.DataFrame({'coef':sgd_reg.coef_,\n",
    "                            'mag':np.abs(sgd_reg.coef_),\n",
    "                            'pred':X.columns})\n",
    "value_coefs.sort_values('mag', ascending=False, inplace=True)\n",
    "value_coefs.iloc[0:10, :]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "coef\tmag\tpred\n",
    "160\t38439.456150\t38439.456150\tsqft\n",
    "152\t32043.484097\t32043.484097\tbeds\n",
    "151\t30316.314014\t30316.314014\tbaths\n",
    "70\t28850.218324\t28850.218324\tneighborhood[T.08E]\n",
    "49\t26165.046578\t26165.046578\tneighborhood[T.05E]\n",
    "47\t25377.302724\t25377.302724\tneighborhood[T.05C]\n",
    "63\t21479.833165\t21479.833165\tneighborhood[T.07B]\n",
    "156\t-21446.703891\t21446.703891\towner_pct\n",
    "159\t-20351.596770\t20351.596770\tvolume\n",
    "162\t18676.553894\t18676.553894\tyear_recorded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Classification with stochastic gradient descent\n",
    "\n",
    "The `SGDClassifier` is very similar to the `SGDRegressor`. The main difference is that the loss functions are changed to regression loss functions.\n",
    "\n",
    "**Arguments**\n",
    "- `loss`: `['log', ...]`\n",
    "    - The `'log'` loss corresponds to solving a logistic regression classifier. This is what I expect you'll use, but there are many other options.\n",
    "- `penalty`: `['none','l1','l2','elasticnet']`\n",
    "    - This defines the penalty on the regression that you would like to solve. The l1 and l2 are the Lasso and Ridge, while the elasticnet is the combination of them both.\n",
    "- `alpha`\n",
    "    - The regularization strength to be used with a chosen penalty. Same as in Lasso and Ridge.\n",
    "- `l1_ratio`\n",
    "    - The mix of the Lasso and Ridge penalties when elasticnet is chosen as the penalty.\n",
    "- `n_iter`\n",
    "    - The number of training \"epochs\" over the data. This is the number of passes that the gradient descent algorithm will make over the data to iteratively fit the weights (defaults to 5).\n",
    "\n",
    "Like `SGDRegressor`, `SGDClassifier` is most often used in tandem with grid searching to find the optimal parameters for certain models. \n",
    "\n",
    "**It is up to you how you want to define the model. You should:**\n",
    "\n",
    "1. Choose a target to classify (you may need to engineer one from existing variables).\n",
    "- Calculate the baseline accuracy.\n",
    "- Select predictors to use.\n",
    "- Standardize your predictor matrix.\n",
    "- Build a stochastic gradient descent solver to fit your model. You will likely want to do some kind of gridsearch to find the optimal parameters for your model.\n",
    "- Describe the model selected through gridsearch and compare the performance to baseline.\n",
    "- Examine and interpret the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'baths', u'beds', u'lot_depth', u'basement_area', u'front_ft',\n",
       "       u'owner_pct', u'rooms', u'property_class', u'neighborhood', u'tax_rate',\n",
       "       u'volume', u'sqft', u'stories', u'year_recorded', u'year_built',\n",
       "       u'zone', u'value'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A:\n",
    "prop_samp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1941    975\n",
       "1940    933\n",
       "1925    886\n",
       "1924    758\n",
       "1926    749\n",
       "1927    677\n",
       "1923    674\n",
       "1939    619\n",
       "1948    612\n",
       "1947    583\n",
       "1908    515\n",
       "1928    485\n",
       "1950    462\n",
       "1946    450\n",
       "1922    448\n",
       "1938    437\n",
       "1951    430\n",
       "1907    429\n",
       "1906    409\n",
       "1931    404\n",
       "1910    357\n",
       "1929    357\n",
       "1930    348\n",
       "1937    347\n",
       "1936    345\n",
       "1944    333\n",
       "1949    319\n",
       "1942    307\n",
       "1912    301\n",
       "1955    253\n",
       "       ... \n",
       "1992    117\n",
       "1965    100\n",
       "1995     95\n",
       "1933     87\n",
       "1985     85\n",
       "1977     84\n",
       "1998     79\n",
       "1973     71\n",
       "1974     69\n",
       "1918     68\n",
       "1902     64\n",
       "1966     63\n",
       "1994     59\n",
       "1970     58\n",
       "1967     54\n",
       "2000     51\n",
       "1976     51\n",
       "1968     45\n",
       "1903     42\n",
       "1934     38\n",
       "1971     36\n",
       "1969     21\n",
       "1901     15\n",
       "1999     15\n",
       "2002      6\n",
       "2001      4\n",
       "2003      4\n",
       "2005      2\n",
       "2004      1\n",
       "2006      1\n",
       "Name: year_built, Length: 106, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_samp['year_built'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets see if we can predict if a house was built past 1980\n",
    "prop_samp['built_past1980'] = prop_samp.year_built.map(lambda x: 1 if x >= 1980 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89296\n"
     ]
    }
   ],
   "source": [
    "# make the target and calculate the baseline:\n",
    "y = prop_samp.built_past1980.values\n",
    "print 1. - np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = '''\n",
    "~ baths + beds + lot_depth + basement_area + front_ft + owner_pct +\n",
    "rooms + property_class + neighborhood + tax_rate + volume + sqft + stories +\n",
    "zone + value\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000, 162)\n"
     ]
    }
   ],
   "source": [
    "X = patsy.dmatrix(f, data=prop_samp, return_type='dataframe')\n",
    "\n",
    "Xs = scaler.fit_transform(X)\n",
    "print y.shape, Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_cls_params = {\n",
    "    'loss':['log'],\n",
    "    'penalty':['l1','l2'],\n",
    "    'alpha':np.logspace(-5,2,50)\n",
    "}\n",
    "\n",
    "sgd_cls = SGDClassifier()\n",
    "sgd_cls_gs = GridSearchCV(sgd_cls, sgd_cls_params, cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   52.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'loss': ['log'], 'alpha': array([  1.00000e-05,   1.38950e-05,   1.93070e-05,   2.68270e-05,\n",
       "         3.72759e-05,   5.17947e-05,   7.19686e-05,   1.00000e-04,\n",
       "         1.38950e-04,   1.93070e-04,   2.68270e-04,   3.72759e-04,\n",
       "         5.17947e-04,   7.19686e-04,...    1.93070e+01,   2.68270e+01,   3.72759e+01,   5.17947e+01,\n",
       "         7.19686e+01,   1.00000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_cls_gs.fit(Xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'alpha': 0.00019306977288832496, 'loss': 'log'}\n",
      "0.96276\n"
     ]
    }
   ],
   "source": [
    "print sgd_cls_gs.best_params_\n",
    "print sgd_cls_gs.best_score_\n",
    "sgd_cls = sgd_cls_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>mag</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>-437.584062</td>\n",
       "      <td>437.584062</td>\n",
       "      <td>zone[T.NCR]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>284.052943</td>\n",
       "      <td>284.052943</td>\n",
       "      <td>zone[T.RC4NC3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-230.655541</td>\n",
       "      <td>230.655541</td>\n",
       "      <td>zone[T.CRNC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>222.399478</td>\n",
       "      <td>222.399478</td>\n",
       "      <td>zone[T.RM2RM3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>-169.587140</td>\n",
       "      <td>169.587140</td>\n",
       "      <td>zone[T.OTCLEM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-149.629774</td>\n",
       "      <td>149.629774</td>\n",
       "      <td>neighborhood[T.03D]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-145.394195</td>\n",
       "      <td>145.394195</td>\n",
       "      <td>neighborhood[T.04M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>-137.643788</td>\n",
       "      <td>137.643788</td>\n",
       "      <td>zone[T.RM3RM4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>-137.489194</td>\n",
       "      <td>137.489194</td>\n",
       "      <td>zone[T.RM1RM4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>-135.792977</td>\n",
       "      <td>135.792977</td>\n",
       "      <td>neighborhood[T.08H]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           coef         mag                 pred\n",
       "108 -437.584062  437.584062          zone[T.NCR]\n",
       "116  284.052943  284.052943       zone[T.RC4NC3]\n",
       "97  -230.655541  230.655541         zone[T.CRNC]\n",
       "134  222.399478  222.399478       zone[T.RM2RM3]\n",
       "110 -169.587140  169.587140       zone[T.OTCLEM]\n",
       "22  -149.629774  149.629774  neighborhood[T.03D]\n",
       "39  -145.394195  145.394195  neighborhood[T.04M]\n",
       "138 -137.643788  137.643788       zone[T.RM3RM4]\n",
       "132 -137.489194  137.489194       zone[T.RM1RM4]\n",
       "73  -135.792977  135.792977  neighborhood[T.08H]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_coefs = pd.DataFrame({'coef':sgd_cls.coef_[0],\n",
    "                            'mag':np.abs(sgd_cls.coef_[0]),\n",
    "                            'pred':X.columns})\n",
    "value_coefs.sort_values('mag', ascending=False, inplace=True)\n",
    "value_coefs.iloc[0:10, :]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "coef\tmag\tpred\n",
    "125\t-692.578967\t692.578967\tzone[T.RH2RH3]\n",
    "129\t-267.151491\t267.151491\tzone[T.RHDRH2]\n",
    "97\t-205.203377\t205.203377\tzone[T.CRNC]\n",
    "99\t-204.529648\t204.529648\tzone[T.FILLMR]\n",
    "110\t202.504292\t202.504292\tzone[T.NCS]\n",
    "139\t-162.959197\t162.959197\tzone[T.RM3RM4]\n",
    "22\t-162.013719\t162.013719\tneighborhood[T.03D]\n",
    "143\t-144.947059\t144.947059\tzone[T.SACTO]\n",
    "73\t-125.919392\t125.919392\tneighborhood[T.08H]\n",
    "115\t-97.406194\t97.406194\tzone[T.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
