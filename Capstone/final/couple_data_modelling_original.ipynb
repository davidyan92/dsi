{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Features Selection to review factors that affect relationship outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model Check\n",
    "# Oversample Minority\n",
    "# Shuffle Predictors and Targets such that predictors point to new targets\n",
    "# Use dataset without Smoteen & Tomek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result from using dataset without Smoteen & Tomek\n",
    "> * Only GridSearchCV LogReg & GridSearchCV SGDClassifier performed normally **(Training Result > Test Result)** under imbalanced dataset \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result from using dataset with Smoteen & Tomek\n",
    "> * All models performed normally "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minority class over Majority class, Reverse Imbalance\n",
    "> * LogReg, Ridge LogReg, Lasso LogReg & Xgboost Classifier perform normally under reversed imbalanced\n",
    "* GridSearchCV LogReg & GridSearchCV SGDClassifier did not perform normally **(Training Result < Test Result)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle Predictors & Targets\n",
    "> * Scores across the models all dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing as pp\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import cross_val_predict, GridSearchCV, train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = pd.read_pickle('./couple_data_xgboost_predictors')\n",
    "# X = pd.read_pickle('./couple_data_predictors')\n",
    "X = pd.read_pickle('./couple_data_without_resample_predictors')\n",
    "# X = pd.read_pickle('./couple_data_rev_imbal_predictors')\n",
    "# X = pd.read_pickle('./couple_data_lasso_predictors')\n",
    "# y = pd.read_pickle('./couple_data_rev_imbal_target')\n",
    "y = pd.read_pickle('./couple_data_without_resample_target')\n",
    "# y = pd.read_pickle('./couple_data_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffling Predictors, swapping rows\n",
    "# for verification only\n",
    "# X = X.sample(frac=1, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scale the resampled features\n",
    "Xs = StandardScaler().fit_transform(X)\n",
    "y = y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRID SEARCH:\n",
      "Best parameters set:\n",
      "f1 score: 0.825022665458\n",
      "\tC: 0.077426368268112694\n",
      "\tpenalty: 'l1'\n",
      "\tsolver: 'liblinear'\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "GRIDSEARCHCV LOGREG RESULT:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      break up       0.72      0.60      0.66       172\n",
      "still together       0.83      0.89      0.86       372\n",
      "\n",
      "   avg / total       0.80      0.80      0.80       544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch for Ridge and Lasso Logistic Regression, optimize C\n",
    "\n",
    "parameters = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'solver':['liblinear'],\n",
    "    'C':np.logspace(-5,0,100)\n",
    "}\n",
    "\n",
    "print (\"GRID SEARCH:\")\n",
    "lr_grid_search = GridSearchCV(LogisticRegression(), parameters, cv=10, verbose=0)\n",
    "lr_grid_search.fit(X_train, y_train)\n",
    "print (\"Best parameters set:\")\n",
    "print('f1 score:', lr_grid_search.best_score_)\n",
    "lr_best_parameters = lr_grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print (\"\\t%s: %r\" % (param_name, lr_best_parameters[param_name]))\n",
    "print (\"-----------------------------------------\")\n",
    "print (\"-----------------------------------------\")\n",
    "print (\"GRIDSEARCHCV LOGREG RESULT:\")\n",
    "clf = lr_grid_search.best_estimator_\n",
    "lr_gs_predicted = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, lr_gs_predicted, labels=[1,0], target_names=['break up','still together']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>mag</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.831808</td>\n",
       "      <td>0.831808</td>\n",
       "      <td>coresident[T.Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-0.420176</td>\n",
       "      <td>0.420176</td>\n",
       "      <td>how_long_ago_first_cohab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.337918</td>\n",
       "      <td>0.337918</td>\n",
       "      <td>married[T.married]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>-0.299578</td>\n",
       "      <td>0.299578</td>\n",
       "      <td>how_long_relationship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.281210</td>\n",
       "      <td>0.281210</td>\n",
       "      <td>parental_approval[T.approve]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.188001</td>\n",
       "      <td>0.188001</td>\n",
       "      <td>parent_alive[T.neither father nor mother are a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.151057</td>\n",
       "      <td>0.151057</td>\n",
       "      <td>couple_relig_comb[T.Protestant or oth Christia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-0.132750</td>\n",
       "      <td>0.132750</td>\n",
       "      <td>partner_yrsed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.114120</td>\n",
       "      <td>0.114120</td>\n",
       "      <td>couple_race_comb[T.other_other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.085298</td>\n",
       "      <td>0.085298</td>\n",
       "      <td>q24_church[T.Yes]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coef       mag                                               pred\n",
       "33 -0.831808  0.831808                                  coresident[T.Yes]\n",
       "51 -0.420176  0.420176                           how_long_ago_first_cohab\n",
       "31 -0.337918  0.337918                                 married[T.married]\n",
       "52 -0.299578  0.299578                              how_long_relationship\n",
       "32 -0.281210  0.281210                       parental_approval[T.approve]\n",
       "9  -0.188001  0.188001  parent_alive[T.neither father nor mother are a...\n",
       "44  0.151057  0.151057  couple_relig_comb[T.Protestant or oth Christia...\n",
       "56 -0.132750  0.132750                                      partner_yrsed\n",
       "47  0.114120  0.114120                    couple_race_comb[T.other_other]\n",
       "18 -0.085298  0.085298                                  q24_church[T.Yes]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top 10 coefficients\n",
    "lr_gs_coef = pd.DataFrame({\n",
    "    'coef':clf.coef_.ravel(),\n",
    "    'mag':np.abs(clf.coef_.ravel()),\n",
    "    'pred':X.columns\n",
    "})\n",
    "lr_gs_coef.sort_values(by=['mag'], ascending=False, inplace=True)\n",
    "lr_gs_coef.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRID SEARCH:\n",
      "Best parameters set:\n",
      "f1 score: 0.827742520399\n",
      "\talpha: 0.0075646332755462909\n",
      "\tl1_ratio: 0.88586679041008254\n",
      "\tlearning_rate: 'optimal'\n",
      "\tloss: 'log'\n",
      "\tpenalty: 'l1'\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "GRIDSEARCHCV SGDCLASSIFIER RESULT:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      break up       0.72      0.59      0.65       172\n",
      "still together       0.83      0.89      0.86       372\n",
      "\n",
      "   avg / total       0.79      0.80      0.79       544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch SGDclassifier with log loss and optimal learning rate\n",
    "sgd_parameters = {\n",
    "    'learning_rate': ['optimal'],\n",
    "    'loss':['log','hinge'],\n",
    "    'penalty': ['l1','l2','elasticnet'],\n",
    "    'alpha': np.logspace(-10,5,100),\n",
    "    'l1_ratio': np.logspace(-1,0,20)\n",
    "}\n",
    "\n",
    "print (\"GRID SEARCH:\")\n",
    "sgd_grid_search = GridSearchCV(SGDClassifier(max_iter=10000, tol=0.0001), sgd_parameters, cv=10, verbose=0)\n",
    "sgd_grid_search.fit(X_train, y_train)\n",
    "print (\"Best parameters set:\")\n",
    "print('f1 score:', sgd_grid_search.best_score_)\n",
    "sgd_best_parameters = sgd_grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(sgd_parameters.keys()):\n",
    "    print (\"\\t%s: %r\" % (param_name, sgd_best_parameters[param_name]))\n",
    "print (\"-----------------------------------------\")\n",
    "print (\"-----------------------------------------\")\n",
    "print (\"GRIDSEARCHCV SGDCLASSIFIER RESULT:\")\n",
    "sgd_clf = sgd_grid_search.best_estimator_\n",
    "sgd_predicted = sgd_clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, sgd_predicted, labels=[1,0], target_names=['break up','still together']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>mag</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.938917</td>\n",
       "      <td>0.938917</td>\n",
       "      <td>coresident[T.Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-0.813247</td>\n",
       "      <td>0.813247</td>\n",
       "      <td>how_long_ago_first_cohab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.349173</td>\n",
       "      <td>0.349173</td>\n",
       "      <td>parent_alive[T.neither father nor mother are a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.288956</td>\n",
       "      <td>0.288956</td>\n",
       "      <td>married[T.married]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.285580</td>\n",
       "      <td>0.285580</td>\n",
       "      <td>parental_approval[T.approve]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.227165</td>\n",
       "      <td>0.227165</td>\n",
       "      <td>couple_relig_comb[T.Protestant or oth Christia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-0.152981</td>\n",
       "      <td>0.152981</td>\n",
       "      <td>partner_yrsed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.145516</td>\n",
       "      <td>0.145516</td>\n",
       "      <td>couple_race_comb[T.other_other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.141000</td>\n",
       "      <td>0.141000</td>\n",
       "      <td>q24_church[T.Yes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.102237</td>\n",
       "      <td>0.102237</td>\n",
       "      <td>q24_public[T.Yes]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coef       mag                                               pred\n",
       "33 -0.938917  0.938917                                  coresident[T.Yes]\n",
       "51 -0.813247  0.813247                           how_long_ago_first_cohab\n",
       "9  -0.349173  0.349173  parent_alive[T.neither father nor mother are a...\n",
       "31 -0.288956  0.288956                                 married[T.married]\n",
       "32 -0.285580  0.285580                       parental_approval[T.approve]\n",
       "44  0.227165  0.227165  couple_relig_comb[T.Protestant or oth Christia...\n",
       "56 -0.152981  0.152981                                      partner_yrsed\n",
       "47  0.145516  0.145516                    couple_race_comb[T.other_other]\n",
       "18 -0.141000  0.141000                                  q24_church[T.Yes]\n",
       "23 -0.102237  0.102237                                  q24_public[T.Yes]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top 10 coefficients\n",
    "sgd_coef = pd.DataFrame({\n",
    "    'coef':sgd_clf.coef_.ravel(),\n",
    "    'mag':np.abs(sgd_clf.coef_.ravel()),\n",
    "    'pred':X.columns\n",
    "})\n",
    "sgd_coef.sort_values(by=['mag'], ascending=False, inplace=True)\n",
    "sgd_coef.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.702702159915\n",
      "base_score: 0.5\n",
      "colsample_bylevel: 1\n",
      "colsample_bytree: 0.8\n",
      "gamma: 0\n",
      "learning_rate: 0.1\n",
      "max_delta_step: 0\n",
      "max_depth: 7\n",
      "min_child_weight: 1\n",
      "missing: -999\n",
      "n_estimators: 1000\n",
      "nthread: 4\n",
      "objective: 'binary:logistic'\n",
      "reg_alpha: 0\n",
      "reg_lambda: 1\n",
      "scale_pos_weight: 1\n",
      "seed: 65\n",
      "silent: 1\n",
      "subsample: 0.8\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "GRIDSEARCHCV XGBCLASSIFIER RESULT:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      break up       0.69      0.64      0.66       172\n",
      "still together       0.84      0.87      0.85       372\n",
      "\n",
      "   avg / total       0.79      0.80      0.79       544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reference link: https://www.kaggle.com/phunter/xgboost-with-gridsearchcv\n",
    "# Credit to Shize's R code and the python re-implementation\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "#brute force scan for all parameters, here are the tricks\n",
    "#usually max_depth is 6,7,8\n",
    "#learning rate is around 0.05, but small changes may make big diff\n",
    "#tuning min_child_weight subsample colsample_bytree can have \n",
    "#much fun of fighting against overfit \n",
    "#n_estimators is how many round of boosting\n",
    "#finally, ensemble xgboost with multiple seeds may reduce variance\n",
    "parameters = {'nthread': [4], #when use hyperthread, xgboost may become slower\n",
    "              'objective': ['binary:logistic'],\n",
    "              'learning_rate': [0.05, 0.1], #so called `eta` value\n",
    "              'max_depth': [6,7,8],\n",
    "              'min_child_weight': [1],\n",
    "              'gamma': [0,0.1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.8],\n",
    "              'silent': [1],\n",
    "              'scale_pos_weight': [1],\n",
    "              'n_estimators': [1000], #number of trees, change it to 1000 for better results\n",
    "              'missing': [-999],\n",
    "              'seed': [65]}\n",
    "\n",
    "xgb_clf = GridSearchCV(xgb_model, parameters, n_jobs=-1, scoring='f1', verbose=1, cv=5)\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "best_parameters = xgb_clf.best_estimator_.get_params()\n",
    "print('f1 score:', xgb_clf.best_score_)\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "print (\"-----------------------------------------\")\n",
    "print (\"-----------------------------------------\")\n",
    "print (\"GRIDSEARCHCV XGBCLASSIFIER RESULT:\")\n",
    "xgb_predicted = xgb_clf.best_estimator_.predict(X_test)\n",
    "print(metrics.classification_report(y_test, xgb_predicted, labels=[1,0], target_names=['break up','still together']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get top 10 coefficients\n",
    "xgb_featimpt = pd.DataFrame({\n",
    "    'importance':xgb_clf.best_estimator_.feature_importances_,\n",
    "    'pred':X.columns\n",
    "})\n",
    "xgb_featimpt = xgb_featimpt[xgb_featimpt.importance > 0]\n",
    "xgb_featimpt.sort_values(by=['importance'], ascending=False, inplace=True)\n",
    "xgb_featimpt.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only GridSearch LogReg & Gridsearch SGDClassifier & xgboost performs normally in an imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for any feature that are removed in this round which might result in the drop in performance\n",
    "xgb_featimpt = pd.DataFrame({\n",
    "    'importance':xgb_clf.best_estimator_.feature_importances_,\n",
    "    'pred':X.columns\n",
    "})\n",
    "xgb_featimpt[xgb_featimpt.importance <= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop in the above features might be the cause of the drop from previous score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/deap/tools/_hypervolume/pyhv.py:33: ImportWarning: Falling back to the python version of hypervolume module. Expect this to be very slow.\n",
      "  \"module. Expect this to be very slow.\", ImportWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Try TPOT\n",
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "pipeline_optimizer = TPOTClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_optimizer = TPOTClassifier(generations=5, population_size=20, cv=5,\n",
    "                                    random_state=42, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  33%|███▎      | 40/120 [00:36<00:59,  1.34pipeline/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.8385921338862516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  50%|█████     | 60/120 [01:07<02:12,  2.20s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.8385921338862516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  67%|██████▋   | 80/120 [03:11<07:05, 10.64s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.8385921338862516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  83%|████████▎ | 100/120 [13:09<09:17, 27.88s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.8394847706612412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 5 - Current best internal CV score: 0.8394847706612412\n",
      "\n",
      "Best pipeline: ExtraTreesClassifier(input_matrix, bootstrap=False, criterion=entropy, max_features=0.5, min_samples_leaf=1, min_samples_split=8, n_estimators=100)\n",
      "0.801470588235\n"
     ]
    }
   ],
   "source": [
    "pipeline_optimizer.fit(X_train, y_train)\n",
    "print(pipeline_optimizer.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "      break up       0.73      0.60      0.66       172\n",
      "still together       0.83      0.90      0.86       372\n",
      "\n",
      "   avg / total       0.80      0.80      0.80       544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yhat = pipeline_optimizer.predict(X_test)\n",
    "print(metrics.classification_report(y_test, yhat, labels=[1,0], target_names=['break up','still together']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Models from TPOT\n",
    "> * Extra Trees Classifier - **precision: 0.80** | **recall: 0.80** | **f1-score: 0.80**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
