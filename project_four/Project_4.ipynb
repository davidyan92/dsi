{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \n",
    "# Job titles to search for:\n",
    "* data scientist\n",
    "* data analyst\n",
    "* data architect\n",
    "* data engineer\n",
    "* statistician\n",
    "* database administrator\n",
    "* business analyst\n",
    "* data analytics manager\n",
    ">\n",
    "# Countries to search in:\n",
    "* Singapore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Each page has 15 job descriptions, 5 advertised jobs\n",
    "# url = 'https://www.indeed.com.sg/jobs?q=data+scientist&l=Singapore&start='\n",
    "# Assumption is that all job information gathered are data-related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize search parameters and dataframe\n",
    "country_set = ['singapore']\n",
    "search_string = ['data science','data scientist','data analyst','data architect','data engineer', \\\n",
    "                 'statistician','database administrator','business analyst','data analytics manager']\n",
    "columns = [\"job_category\",\"job_title\", \"company_name\", \"location\", \"summary\", \"salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3700 entries, 0 to 3699\n",
      "Data columns (total 6 columns):\n",
      "job_category    3700 non-null object\n",
      "job_title       3700 non-null object\n",
      "company_name    3017 non-null object\n",
      "location        3700 non-null object\n",
      "summary         3699 non-null object\n",
      "salary          124 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 173.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Initialize container to store all job postings\n",
    "jobs_list = []\n",
    "\n",
    "# Iterate through search parameters and store relevant data in respective columns in dataframe\n",
    "for country in country_set:\n",
    "    for query in search_string:\n",
    "        \n",
    "        url = 'https://www.indeed.com.sg/jobs?q=' + '+'.join([word for word in query.split()]) + '&l=' + country + '&start='\n",
    "        time.sleep(1)\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text, 'lxml')\n",
    "        jobs_count = soup.find_all(name='div', attrs={'id':'searchCount'})[0].get_text()\n",
    "        \n",
    "        # Get maximum number of jobs to iterate over all pages\n",
    "        max_jobs = int(re.sub('[^0-9a-zA-Z]+', '', jobs_count.split()[-1]))\n",
    "        \n",
    "        for start_number in range(0,max_jobs,10):\n",
    "            time.sleep(1)\n",
    "            url_page = url + str(start_number)\n",
    "            page = requests.get(url_page)\n",
    "            soup = BeautifulSoup(page.text, 'lxml')\n",
    "            \n",
    "            # Get all advertised job descriptions\n",
    "            regex = re.compile('.*row.*')\n",
    "            jobs = soup.find_all(name='div', attrs={'class':regex})\n",
    "            \n",
    "            # Get job title from job description\n",
    "            for job in jobs:\n",
    "\n",
    "                job_title = job.find(name='a', attrs={'data-tn-element':'jobTitle'})\n",
    "                company = job.find(name='span', attrs={'class':'company'})\n",
    "                location = job.find(name='span', attrs={'class':'location'})\n",
    "                summary = job.find(name='span', attrs={'class':'summary'})\n",
    "                salary = job.find(name='span', attrs={'class':'no-wrap'})\n",
    "\n",
    "                # Put default for missing variables\n",
    "                if job_title != None:\n",
    "                    job_title_result = job_title.get_text()\n",
    "                    job_title_result = job_title_result.replace('\\n','')\n",
    "                    job_title_result = job_title_result.strip()\n",
    "                else:\n",
    "                    job_title_result = np.nan\n",
    "\n",
    "                if company != None:\n",
    "                    company_result = company.get_text()\n",
    "                    company_result = company_result.replace('\\n','')\n",
    "                    company_result = company_result.strip()\n",
    "                else:\n",
    "                    company_result = np.nan\n",
    "\n",
    "                if location != None:\n",
    "                    location_result = location.get_text()\n",
    "                    location_result = location_result.replace('\\n','')\n",
    "                    location_result = location_result.strip()\n",
    "                else:\n",
    "                    location_result = np.nan\n",
    "\n",
    "                if summary != None:\n",
    "                    summary_result = summary.get_text()\n",
    "                    summary_result = summary_result.replace('\\n','')\n",
    "                    summary_result = summary_result.strip()\n",
    "                else:\n",
    "                    summary_result = np.nan\n",
    "\n",
    "                if salary != None:\n",
    "#                   salary_list = [s for s in re.findall(r'\\d+(?:[\\d,.]*\\d)', salary.get_text())]\n",
    "#                   salary_list_mod = [int(re.sub('[^0-9a-zA-Z]+', '', s)) for s in salary_list]\n",
    "                    salary_result = salary.get_text()\n",
    "                    salary_result = salary_result.replace('\\n','')\n",
    "                    salary_result = salary_result.strip()\n",
    "                else:\n",
    "                    salary_result = np.nan\n",
    "\n",
    "                # Append to list\n",
    "                job_category = '_'.join([word for word in query.split()])\n",
    "                jobs_list.append([job_category,job_title_result, company_result, location_result, summary_result, salary_result])\n",
    "\n",
    "# Convert jobs list to dataframe\n",
    "df = pd.DataFrame(jobs_list, columns = columns)\n",
    "# drop all duplicated job postings based on summary\n",
    "df.drop_duplicates(subset=['summary'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# save dataframe in pickle to not waste time scrapping again\n",
    "# df.to_pickle('indeed_data_related_jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle('./indeed_data_related_jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124 entries, 5 to 3667\n",
      "Data columns (total 6 columns):\n",
      "job_category    124 non-null object\n",
      "job_title       124 non-null object\n",
      "company_name    124 non-null object\n",
      "location        124 non-null object\n",
      "summary         124 non-null object\n",
      "salary          124 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 6.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df1[~df1.salary.isnull()].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
