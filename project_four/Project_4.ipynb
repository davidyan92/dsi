{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \n",
    "# Job titles to search for:\n",
    "* data scientist\n",
    "* data analyst\n",
    "* data architect\n",
    "* data engineer\n",
    "* statistician\n",
    "* database administrator\n",
    "* business analyst\n",
    "* data analytics manager\n",
    ">\n",
    "# Countries to search in:\n",
    "* Singapore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Each page has 15 job descriptions, 5 advertised jobs\n",
    "# url = 'https://www.indeed.com.sg/jobs?q=data+scientist&l=Singapore&start='\n",
    "# Assumption is that all job information gathered are data-related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize search parameters and dataframe\n",
    "# 'my',\n",
    "country_set = ['sg','my']\n",
    "search_string = ['data scientist', 'data analyst', 'data architect', 'data engineer',\n",
    "       'statistician', 'database administrator', 'business analyst',\n",
    "       'data analytics manager']\n",
    "columns = [\"job_category\",\"job_title\", \"company_name\", \"location\", \"summary\", \"salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7388 entries, 0 to 7387\n",
      "Data columns (total 6 columns):\n",
      "job_category    7388 non-null object\n",
      "job_title       7388 non-null object\n",
      "company_name    6245 non-null object\n",
      "location        7388 non-null object\n",
      "summary         6647 non-null object\n",
      "salary          332 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 346.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Initialize container to store all job postings\n",
    "jobs_list = []\n",
    "\n",
    "# Iterate through search parameters and store relevant data in respective columns in dataframe\n",
    "for country in country_set:\n",
    "    for query in search_string:\n",
    "        \n",
    "        url = 'https://www.indeed.com.' + country + '/jobs?q=' + '+'.join([word for word in query.split()]) + '&start='\n",
    "        time.sleep(1)\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text, 'lxml')\n",
    "        jobs_count = soup.find_all(name='div', attrs={'id':'searchCount'})[0].get_text()\n",
    "        \n",
    "        # Get maximum number of jobs to iterate over all pages\n",
    "        max_jobs = int(re.sub('[^0-9a-zA-Z]+', '', jobs_count.split()[-1]))\n",
    "        \n",
    "        for start_number in range(0,max_jobs,10):\n",
    "            time.sleep(1)\n",
    "            url_page = url + str(start_number)\n",
    "            page = requests.get(url_page)\n",
    "            soup = BeautifulSoup(page.text, 'lxml')\n",
    "            \n",
    "            # Get all advertised job descriptions\n",
    "            regex = re.compile('.*row.*')\n",
    "            jobs = soup.find_all(name='div', attrs={'class':regex})\n",
    "            \n",
    "            # Get job title from job description\n",
    "            for job in jobs:\n",
    "\n",
    "                job_title = job.find(name='a', attrs={'data-tn-element':'jobTitle'})\n",
    "                company = job.find(name='span', attrs={'class':'company'})\n",
    "                location = job.find(name='span', attrs={'class':'location'})\n",
    "                summary = job.find(name='span', attrs={'class':'summary'})\n",
    "                salary = job.find(name='span', attrs={'class':'no-wrap'})\n",
    "\n",
    "                # Put default for missing variables\n",
    "                if job_title != None:\n",
    "                    job_title_result = job_title.get_text()\n",
    "                    job_title_result = job_title_result.replace('\\n','')\n",
    "                    job_title_result = job_title_result.strip()\n",
    "                else:\n",
    "                    job_title_result = np.nan\n",
    "\n",
    "                if company != None:\n",
    "                    company_result = company.get_text()\n",
    "                    company_result = company_result.replace('\\n','')\n",
    "                    company_result = company_result.strip()\n",
    "                else:\n",
    "                    company_result = np.nan\n",
    "\n",
    "                if location != None:\n",
    "                    location_result = location.get_text()\n",
    "                    location_result = location_result.replace('\\n','')\n",
    "                    location_result = location_result.strip()\n",
    "                else:\n",
    "                    location_result = np.nan\n",
    "\n",
    "                if summary != None:\n",
    "                    summary_result = summary.get_text()\n",
    "                    summary_result = summary_result.replace('\\n','')\n",
    "                    summary_result = summary_result.strip()\n",
    "                else:\n",
    "                    summary_result = np.nan\n",
    "\n",
    "                if salary != None:\n",
    "\n",
    "                    salary_result = salary.get_text()\n",
    "                    salary_result = salary_result.replace('\\n','')\n",
    "                    salary_result = salary_result.strip()\n",
    "                else:\n",
    "                    salary_result = np.nan\n",
    "\n",
    "                # Append to list\n",
    "                job_category = '_'.join([word for word in query.split()])\n",
    "                jobs_list.append([job_category,job_title_result, company_result, location_result, summary_result, salary_result])\n",
    "\n",
    "# Convert jobs list to dataframe\n",
    "df = pd.DataFrame(jobs_list, columns = columns)\n",
    "# drop all duplicated job postings based on summary\n",
    "df.drop_duplicates(subset=['summary'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5815 entries, 0 to 7387\n",
      "Data columns (total 6 columns):\n",
      "job_category    5815 non-null object\n",
      "job_title       5815 non-null object\n",
      "company_name    4945 non-null object\n",
      "location        5815 non-null object\n",
      "summary         5814 non-null object\n",
      "salary          284 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 318.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# save dataframe in pickle to not waste time scrapping again\n",
    "df.drop_duplicates(subset=['summary'], inplace=True)\n",
    "df.to_pickle('indeed_data_related_jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle('./indeed_data_related_jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df1.dropna(subset=['company_name', 'summary'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle('./indeed_data_related_jobs')\n",
    "df1.dropna(subset=['company_name', 'summary'], inplace=True)\n",
    "# convert all to small letters if string\n",
    "df1 = df1.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "# remove numbers from job titles\n",
    "from string import digits\n",
    "df1.job_title = df1.job_title.map(lambda x: x.translate(str.maketrans('', '', digits)).strip())\n",
    "# remove business licence numbers\n",
    "df1.company_name = df1.company_name.map(lambda x: x[:x.index(', ea licence')] if x.find(', ea licence') != -1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.job_title.map(lambda x: x if x.find('data') >= 0 or x.find('business analyst') >= 0 or \\\n",
    "                  x.find('business intelligence') >= 0 else np.nan).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data_scientist', 'data_analyst', 'data_architect', 'data_engineer',\n",
       "       'statistician', 'database_administrator', 'business_analyst',\n",
       "       'data_analytics_manager'], dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.job_category.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question 1:\n",
    "# Will use bag of words model to classify high vs low salary\n",
    "# Gather all words associated with low salary\n",
    "# Gather all words associated with high salary\n",
    "# Get their significance by calculating their frequency\n",
    "# use log reg and decision tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
