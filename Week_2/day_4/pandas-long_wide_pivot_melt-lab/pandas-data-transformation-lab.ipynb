{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "## Practice Data Format Transformations: \"Long\" vs. \"Wide\" Format\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "In this lab, you will practice going between long and wide formats in `pandas`, dive deeper into `.melt()` and `.pivot_tables()`, and explore the pitfalls of hierarchical indices that we covered in the lesson.\n",
    "\n",
    "\n",
    "Recall that **long format data** is structured so that:\n",
    "\n",
    "- There are potentially multiple `ID` (identification) columns.\n",
    "- There are pairs of columns such as `variable:value` that match a variable key to a value. (In the simplest case, there would be a single `variable` column and a single `value` column).\n",
    "- The `variable` column corresponds to the multiple variable columns in a wide format data set. Instead of a column for each variable, you have a row for each `variable:value` pair *per ID*. \n",
    "- This is a standard format for SQL databases because it makes it easier to join different tables together with keys.\n",
    "\n",
    "And **wide format data** is structured so that: \n",
    "\n",
    "- There are multiple `ID` _and_ `value` columns. In other words, there is a column for every \"variable\" with its own unique values.\n",
    "- The format has the conceptual simplicity of a single column of values per variable, as well as a more compact matrix.\n",
    "- It is not as useful for SQL-style operations: It can make it much harder or even impossible to join tables together on a value.\n",
    "- It can be useful in `pandas` when you need to perform operations on variables **across columns**; for example, multiplying columns together to create a new column.\n",
    "- It is the most commonly used format for data modeling (with some exceptions). I'll explain why when we get into the subject next week.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A: The Humor Styles Data Set\n",
    "\n",
    "We are going to explore a data set in which people answered a questionnaire about their \"humor styles.\" The study tries to get at the differences in people's senses of humor as well as their relationships with humor.\n",
    "\n",
    "---\n",
    "\n",
    "### A.1: 32 Questions\n",
    "\n",
    "Subjects reacted to **32** different statements, outlined here:\n",
    "\n",
    "1. I usually don't laugh or joke with other people.\n",
    "2. If I feel depressed, I can cheer myself up with humor.\n",
    "3. If someone makes a mistake, I will tease them about it.\n",
    "4. I let people laugh at me or make fun of me at my expense more than I should.\n",
    "5. I don't have to work very hard to make other people laugh. I am a naturally humorous person.\n",
    "6. Even when I'm alone, I am often amused by the absurdities of life.\n",
    "7. People are never offended or hurt by my sense of humor.\n",
    "8. I will often get carried away in putting myself down if it makes family or friends laugh.\n",
    "9. I rarely make other people laugh by telling funny stories about myself.\n",
    "10. If I am feeling upset or unhappy, I usually try to think of something funny about the situation to make myself feel better.\n",
    "11. When telling jokes or saying funny things, I am usually not concerned about how other people are taking it.\n",
    "12. I often try to make people like or accept me more by saying something funny about my own weaknesses, blunders, or faults.\n",
    "13. I laugh and joke a lot with my closest friends.\n",
    "14. My humorous outlook on life keeps me from getting overly upset or depressed about things.\n",
    "15. I do not like it when people use humor as a way of criticizing or putting someone down.\n",
    "16. I don't often say funny things to put myself down.\n",
    "17. I usually don't like to tell jokes or amuse people.\n",
    "18. If I'm by myself and I'm feeling unhappy, I make an effort to think of something funny to cheer myself up.\n",
    "19. Sometimes I think of something that is so funny that I can't stop myself from saying it, even if it is not appropriate for the situation.\n",
    "20. I often go overboard in putting myself down when I am making jokes or trying to be funny.\n",
    "21. I enjoy making people laugh.\n",
    "22. If I am feeling sad or upset, I usually lose my sense of humor.\n",
    "23. I never participate in laughing at others even if all my friends are doing it.\n",
    "24. When I am with friends or family, I often seem to be the one that other people make fun of or joke about.\n",
    "25. I don't often joke around with my friends.\n",
    "26. It is my experience that thinking about some amusing aspect of a situation is often a very effective way of coping with problems.\n",
    "27. If I don't like someone, I often use humor or teasing to put them down.\n",
    "28. If I am having problems or feeling unhappy, I often cover it up by joking around so that even my closest friends don't know how I really feel.\n",
    "29. I usually can't think of witty things to say when I'm with other people.\n",
    "30. I don't need to be with other people to feel amused. I can usually find things to laugh about even when I'm by myself.\n",
    "31. Even if something is really funny to me, I will not laugh or joke about it if someone will be offended.\n",
    "32. Letting others laugh at me is my way of keeping my friends and family in good spirits.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2: Response Codes\n",
    "\n",
    "For each question, there were five possible response codes (a \"Likert scale\") that corresponded to different answers. There was also a code to indicate no response by that subject.\n",
    "\n",
    "    1 == \"Never or very rarely true\"\n",
    "    2 == \"Rarely true\"\n",
    "    3 == \"Sometimes true\"\n",
    "    4 == \"Often true\"\n",
    "    5 == \"Very often or always true\n",
    "    [-1 == Did not select an answer]\n",
    "\n",
    "---\n",
    "\n",
    "You can find more information about the questionnaire [here](https://en.wikipedia.org/wiki/Humor_styles).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B: Load the Modules\n",
    "\n",
    "Let's load the standard modules we always use. None of these are new to you.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data modules\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting modules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Make sure charts appear in the notebook:\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## C: Load and Examine the Data\n",
    "\n",
    "The data set is stored in your **```datasets```** directory.\n",
    "\n",
    "The data set is called **```hsq_data.csv```**. `hsq`, as you might expect, stands for \"Humor Styles Questionnaire.\"\n",
    "\n",
    "[There is also a file called **```hsq_codebook.txt```**, which is a text file containing the information I detailed above. You can examine it if you'd like.]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.1: Create a path string and load it into `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hsq_path = './datasets/hsq_data.csv'\n",
    "\n",
    "hsq = pd.read_csv(hsq_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### C.2 Look at the header.\n",
    "\n",
    "Let's make sure it looks like what we expect and that the data didn't load incorrectly. This, of course, is always good practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q30</th>\n",
       "      <th>Q31</th>\n",
       "      <th>Q32</th>\n",
       "      <th>affiliative</th>\n",
       "      <th>selfenhancing</th>\n",
       "      <th>agressive</th>\n",
       "      <th>selfdefeating</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10    ...     Q30  Q31  Q32  \\\n",
       "0   2   2   3   1   4   5   4   3   4    3    ...       4    2    2   \n",
       "1   2   3   2   2   4   4   4   3   4    3    ...       4    3    1   \n",
       "2   3   4   3   3   4   4   3   1   2    4    ...       5    4    2   \n",
       "3   3   3   3   4   3   5   4   3  -1    4    ...       5    3    3   \n",
       "4   1   4   2   2   3   5   4   1   4    4    ...       5    4    2   \n",
       "\n",
       "   affiliative  selfenhancing  agressive  selfdefeating  age  gender  accuracy  \n",
       "0          4.0            3.5        3.0            2.3   25       2       100  \n",
       "1          3.3            3.5        3.3            2.4   44       2        90  \n",
       "2          3.9            3.9        3.1            2.3   50       1        75  \n",
       "3          3.6            4.0        2.9            3.3   30       2        85  \n",
       "4          4.1            4.1        2.9            2.0   52       1        80  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the header, it's apparent we have **32 columns for each question**. But, if we scroll over to the right, we can see that there are **seven columns of subject properties**.\n",
    "\n",
    "What are these properties? Some are clear and some are not.\n",
    "\n",
    "#### Styles of Humor:\n",
    "\n",
    "1. **Affiliative**\n",
    "    - The style of humor used to enhance one's relationships with others in a positive and benevolent way. \n",
    "2. **Self-enhancing** \n",
    "    - The style of humor related to having a good-natured attitude toward life and the ability to laugh at yourself, your circumstances, and the idiosyncrasies of life in a constructive, non-detrimental manner.\n",
    "3. **Aggressive** \n",
    "    - The style of humor that is potentially detrimental toward others. This type of humor is characterized by the use of sarcasm, put-downs, teasing, criticism, ridicule, and other types of humor at the expense of others.   \n",
    "4. **Self-defeating** \n",
    "    - The style of humor is characterized by the use of potentially detrimental humor toward one's self in order to gain approval from others. Individuals with high scores in this dimension engage in self-disparaging humor in which laughter is often at their own expense.\n",
    "    \n",
    "These dimensions of humor were calculated from the questionnaire responses. \n",
    "\n",
    "- The two positive dimensions of humor are: **affiliative** and **self-enhancing**. \n",
    "- The two _(purportedly)_ negative dimensions of humor are: **aggressive** and **self-defeating**.\n",
    "\n",
    "We'll calculate these manually later to practice column-wise operations in `pandas`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Demographics and Self-Reported Accuracy\n",
    "\n",
    "The demographic columns are:\n",
    "\n",
    "- **`age`**\n",
    "- **`gender`**\n",
    "    - 1 == male\n",
    "    - 2 == female\n",
    "    - 3 == other\n",
    "\n",
    "It's useful to have demographics for each subject in a data set. We'll explore the reasons for this later when we start doing regressions and classifications.\n",
    "\n",
    "The **accuracy** column is the self-reported accuracy of the responses by the subjects themselves — i.e., how accurate they thought their answers were on a scale from 0 to 100.\n",
    "\n",
    "**If a subject entered 0 for accuracy, this actually means they didn't want to be included in the research.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### C.3: Data shape\n",
    "\n",
    "Let's start looking at our data. Print out the shape of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### C.4: Describe the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C.4.1** Print out the names of the columns. You can see that aggressive is misspelled as \"agressive.\" Replace the name of that column specifically using the built-in ```.rename()``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C.4.2** Use the built-in `.describe()` function to look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C.4.3** The maximum age is 44,849, which is obviously impossible. Clearly, there was at least one subject who entered their age incorrectly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C.4.4** Calculate and print just the standard deviation for the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C.4.5** There are three examples of potentially bad data in this data set:\n",
    "\n",
    "1. The questions have different standard deviations, but we know that the range for each is restricted. This means that, for the questions with **higher standard deviations**, there is **more variability in the responses**. \n",
    "2. The standard deviation for age is 1,371, which is higher than any possible age range. This is an example of how outliers affect a lot of statistical measures.\n",
    "3. The standard deviation is lower for the humor style columns. On average, people's values for these attributes are closer together. (Keep in mind, however, that this might just be because the range is \"shrunk.\" This is why it is important to look at both and plot. There are also `-1`s in the responses that can skew the answers' distributions, as we will see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C.4.6** Using `seaborn`, plot the distribution for `Q15` and the distribution for `aggressive`.\n",
    "\n",
    "[**Note:** You can set ```sns.set(rc={\"figure.figsize\": (12, 12)})```. Entering this before the distribution plot will set the figure size to 12x12, similar to using the `fig = plt.figure(figsize=(12,12))` pattern. This is just another way to accomplish the same thing, so use whichever you prefer.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C.4.7** Based on the plot's \"tighter\" distribution, it appears that the calculation of the `aggressive` style lowers the variability. Then again, the question distribution is far from normal, so the standard deviation measure is not that descriptive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## D: Convert the Data From Wide to Long Format\n",
    "\n",
    "### D.1: Make the question columns clearer.\n",
    "\n",
    "**D.1.1** Before we transform our DataFrame to long format, we should make the questions more descriptive so we know what they're referencing. Use the provided dictionary of question numbers and names to transform the column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_change = {\n",
    "    'Q1':'usually_dont_laugh',\n",
    "    'Q2':'if_depressed_use_humor',\n",
    "    'Q3':'tease_others_mistakes',\n",
    "    'Q4':'let_others_laugh_at_me',\n",
    "    'Q5':'make_others_laugh_easy',\n",
    "    'Q6':'when_alone_amused',\n",
    "    'Q7':'my_humor_never_offensive',\n",
    "    'Q8':'use_self_deprecation',\n",
    "    'Q9':'rarely_make_laugh_stories',\n",
    "    'Q10':'if_upset_use_humor',\n",
    "    'Q11':'dont_care_impact_jokes',\n",
    "    'Q12':'self_deprecate_to_befriend',\n",
    "    'Q13':'laugh_alot_with_friends',\n",
    "    'Q14':'humorous_outlook_improves_mood',\n",
    "    'Q15':'dislike_mean_humor',\n",
    "    'Q16':'dont_self_deprecate',\n",
    "    'Q17':'dont_like_telling_jokes',\n",
    "    'Q18':'when_alone_try_laugh',\n",
    "    'Q19':'joke_when_inappropriate',\n",
    "    'Q20':'harshly_self_deprecate',\n",
    "    'Q21':'enjoy_making_others_laugh',\n",
    "    'Q22':'if_sad_cant_laugh',\n",
    "    'Q23':'never_use_mean_humor',\n",
    "    'Q24':'friends_often_tease_me',\n",
    "    'Q25':'dont_often_joke',\n",
    "    'Q26':'humor_coping_mechanism',\n",
    "    'Q27':'tease_disliked_people',\n",
    "    'Q28':'hide_unhappiness_humor',\n",
    "    'Q29':'cant_think_witty_things',\n",
    "    'Q30':'dont_need_others_amused',\n",
    "    'Q31':'if_mean_wont_laugh',\n",
    "    'Q32':'allow_others_tease_me'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D.1.2** Print out the columns and check the header to make sure they were renamed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### D.2: Add a `subject_id` column.\n",
    "\n",
    "We have an index that identifies the rows, but we'll want a column that contains the ID for each subject so we can keep track of which rows correspond with which subject.\n",
    "\n",
    "If this is not clear, don't worry. The reason we are doing this will become clear once we visualize the long form data.\n",
    "\n",
    "**D.2.1** Create an ID array containing the length of our data's rows in which each element is unique.\n",
    "\n",
    "[**Note:** Don't call this variable \"ID,\" as this is reserved. In Jupyter Notebook, green font indicates a reserved name. If a variable you're typing turns green, you should revise it.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D.2.2** Add a new column to your data set that contains the values of the subject IDs array. Call it `subject_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### D.3: Transform the data to long format.\n",
    "\n",
    "We're now going to transform our data set from **wide** to **long** format.\n",
    "\n",
    "The `pandas` function to convert a wide data set to a long data set is **```pd.melt()```**.\n",
    "\n",
    "Here is an example of the function call for a fictional data set:\n",
    "\n",
    "```python\n",
    "id_theft_long = pd.melt(id_theft_wide,\n",
    "                        id_vars=['full_name','birth_date'],\n",
    "                        value_vars=['ccv','zip_code','credit_card_number','pin','ssn'],\n",
    "                        var_name='personal_info',\n",
    "                        value_name='info_value')\n",
    "```\n",
    "\n",
    "So, what are the inputs for this function?\n",
    "\n",
    "- **```id_theft_wide```:** This is my wide format data set with people's personal info.\n",
    "- **```id_vars```:** These are the columns that are _already identifiers_ or can otherwise not be included in `value_vars` because they are a different data type.\n",
    "- **```value_vars```:** These are the columns that will now be represented in a single value column.\n",
    "- **```var_name```:** This is the name of the new, single column that will contain the identifiers for each value by row. The `value_var` columns are now represented in a single column.\n",
    "- **```value_name```:** This is the name of the new single column that contains the values from the `value_vars` columns.\n",
    "\n",
    "**D.3.1** Convert your data set to long format, assigned it to a new DataFrame.\n",
    "\n",
    "- Your `id_vars` will be:\n",
    "    - Subject id\n",
    "    - Age\n",
    "    - Gender\n",
    "- Your ```value_vars``` will be the names of your question, accuracy, and four humor style columns.\n",
    "- Make ```var_name``` \"variable.\"\n",
    "- Make ```value_name``` \"value.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D.3.2** Look at the header. Print the shape of the long DataFrame, as well as the unique values in the `variable` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D.3.3** Print the entire subset of the DataFrame where ```subject_id == 10```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D.3.4** Why would the row index for the subset be increasing but there still be such a big difference between them for subject 10?\n",
    "\n",
    "The ```.melt()``` function is not putting the long DataFrame in order of subject ID. Instead, it is ordering the DataFrame by one of the other variables first. Because of that, the different rows that correspond to subject 10 are spread out across the DataFrame.\n",
    "\n",
    "This is why it is important to add the `subject_id` column prior to converting to long format and use it as an ID column. Without it, we would not know which rows corresponded with which subjects after conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D.3.5** Figure out a way to order the index by `subject_id`. Google it if you need to. Reset the index of the sorted DataFrame, and drop the old index with `drop=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## E: Clean the Data Set and Transform the Variables\n",
    "\n",
    "Transformation and manipulation of variables within data subsets is an essential data science skill!\n",
    "\n",
    "Cleaning is also important. Cleaning data includes, but is not limited to, removing \"bad\" data or any data that should be excluded from your analyses, changing data types, fixing \"bad\" data, and restructuring data for analysis.\n",
    "\n",
    "### E.1: Convert the `gender` column to a string representation.\n",
    "\n",
    "Recall that:\n",
    "    \n",
    "    1 == 'male'\n",
    "    2 == 'female'\n",
    "    3 == 'other'\n",
    "\n",
    "Let's make the `gender` column more readable. Convert this numeric column to a string column that contains the `gender` labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### E.2: Removing subjects from the data set.\n",
    "\n",
    "**E.2.1** Users who did not respond to certain questions will have potentially unreasonable values for their humor style ratings. \n",
    "\n",
    "Find the users who responded ```-1``` on any of the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E.2.2** Remove all rows from the data sets that correspond to the bad users.\n",
    "\n",
    "HINTS:\n",
    "    \n",
    "- The **```~```** operator can invert a logical condition/Boolean array.\n",
    "- The built-in **```.isin()```** function takes a list of values and returns a Boolean array that indicates if any of the Series or DataFrame values were members of the list.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E.2.3** Subjects who entered 0 for accuracy didn't want to be part of the research. Respecting their wishes, check if any entered 0 for accuracy and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E.2.4** Find the subjects who reported an age older than 100 and remove them, because they're lying. \n",
    "  \n",
    "_While some people can live to be 100 years old, nobody who makes it that far knows how to take an online survey._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### E.3: Transform the variables, inverting some.\n",
    "\n",
    "Some of the scales need to be reversed. Next, we'll transform variables so that the valence of the 1-5 Likert scale always goes from negative to positive.\n",
    "\n",
    "For example, the scale for this question is already correctly rated from 1 to 5:\n",
    "\n",
    "    Even if I'm by myself, I'm often amused by the absurdity of life.\n",
    "    \n",
    "This one, on the other hand, needs to be reversed, as the `1` value actually corresponds to a positive humor style:\n",
    "\n",
    "    I usually don't laugh or joke around much with other people.\n",
    "    \n",
    "The following is a list questions that need to be inverted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inverted_questions = ['usually_dont_laugh',\n",
    "                      'tease_others_mistakes',\n",
    "                      'let_others_laugh_at_me',\n",
    "                      'rarely_make_laugh_stories',\n",
    "                      'use_self_deprecation',\n",
    "                      'tease_disliked_people',\n",
    "                      'cant_think_witty_things',\n",
    "                      'allow_others_tease_me',\n",
    "                      'harshly_self_deprecate',\n",
    "                      'dont_often_joke',\n",
    "                      'if_sad_cant_laugh',\n",
    "                      'dont_like_telling_jokes',\n",
    "                      'dont_care_impact_jokes',\n",
    "                      'self_deprecate_to_befriend',\n",
    "                      'friends_often_tease_me',\n",
    "                      'joke_when_inappropriate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E.3.1** Write a function that will accept a score value and \"invert\" the score — that is to say:\n",
    "\n",
    "    1 -> 5\n",
    "    2 -> 4\n",
    "    3 -> 3\n",
    "    4 -> 2\n",
    "    5 -> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E.3.2** Apply the score inverter function to the values where the variable is included in the ```inverted_question``` list, reassigning the ```value``` column at those locations.\n",
    "\n",
    "Don't forget about the ```.isin()``` function for Series, as well as the ```.map()``` or ```.apply()``` functions for element-related Series operations!\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.isin.html\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.map.html\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.Series.apply.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## F: Transforming the Data Set Back to Wide Format\n",
    "\n",
    "Now we will transform the long format DataFrame back to wide format.\n",
    "\n",
    "We are going to be using the powerful **```pd.pivot_table()```** function. \n",
    "\n",
    "---\n",
    "\n",
    "### F.1: Use `pd.pivot_table()` to re-widen your data.\n",
    "\n",
    "The ```pd.pivot_table()``` function takes a variety of arguments. For now, let's just set the keyword arguments and corresponding values outlined below:\n",
    "\n",
    "- **`data`**: The first argument is the DataFrame you want to pivot.\n",
    "\n",
    "- **`index`**: The key(s) to group by along the pivot table indices, or rows. These \"keys\" are column names in your DataFrame.\n",
    "\n",
    "```python\n",
    "index = ['subject_id','age','gender']\n",
    "```\n",
    "\n",
    "- **`columns`**: The key(s) to group by along the pivot table columns. These are also names or column names.\n",
    "\n",
    "```python\n",
    "columns = ['variable']\n",
    "```\n",
    "\n",
    "- **`values`**: The key(s) that are the values to \"aggregate.\" We'll cover more on aggregation soon, so don't worry about it for now.\n",
    "\n",
    "```python\n",
    "values = 'value'\n",
    "```\n",
    "\n",
    "- **`aggfunc`**: This should be the count, which can be the function `len`.\n",
    "\n",
    "```python\n",
    "aggfunc = len\n",
    "```\n",
    "\n",
    "**F.1.1** Create a new widened DataFrame from your long data set using the specified keyword arguments above. Print out the head and shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F.1.2 Reset the index and turn the data into long format.\n",
    "\n",
    "The long form melted data set should have three columns: `gender`, `variable`, and `count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F.1.3 Merge the `count` long data set into the full long data set.\n",
    "\n",
    "Merge these small counts by `gender` and `variable` with the original long DataFrame.\n",
    "\n",
    "The `count` DataFrame contains two key variables we need to match in the full long DataFrame.\n",
    "\n",
    "Your code would look something like this:\n",
    "\n",
    "```python\n",
    "hsq_long_merged = hsq_long.merge(hsq_count_long, on=['gender','variable'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F.1.4 Use the `.pivot_table()` function to calculate the mean of both the original values and the counts by `gender` and `age` across variables.\n",
    "\n",
    "The code could be something like this:\n",
    "\n",
    "```python\n",
    "value_count_means = pd.pivot_table(hsq_long_merged,\n",
    "                                   index=['gender','age'],\n",
    "                                   columns=['variable'],\n",
    "                                   values=['value', 'count'],\n",
    "                                   aggfunc=np.mean)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### F.2: Understanding the MultiIndex\n",
    "\n",
    "The MultiIndex can appear daunting at first — what is it? How do we use it?\n",
    "\n",
    "**F.2.1** Print out the columns of the `means` DataFrame you created in the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before, the columns were just a list of the column names. Now, they include three attributes:\n",
    "\n",
    "- **Levels**: The list of lists that contains the hierarchy of header labels.\n",
    "- **Labels**: The list of lists that specifies which label goes in which position in the hierarchy.\n",
    "- **Names**: The names of the hierarchical header levels.\n",
    "\n",
    "**F.2.2** Print out the ```.columns.names``` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the name of the second level is `variable`, and the first (top) level reads ```None``` — i.e., no name.\n",
    "\n",
    "Why is the top level ```None```? \n",
    "\n",
    "The name `variable` indicates the category, so to speak, of the bottom-level header labels. Looking at the ```.head()``` printout, you can see that `variable` is just to the left of all the bottom-level headers. The **name of that level is `variable`**, which is the column that the headers were pulled out of in the long data.\n",
    "\n",
    "The top level — `value` — has no name because there aren't any tiers above it, and `pandas` chooses to not give it a name! \n",
    "\n",
    "The names are just an added convenience anyway, as you **index by labels**.\n",
    "\n",
    "---\n",
    "\n",
    "Still confused? Think of it this way: The `value` label at the top spans all of the columns and corresponds to the values in the columns' cells. \n",
    "\n",
    "Remember how the `variable` and `value` columns looked in the long data?\n",
    "\n",
    "```\n",
    "variable       value\n",
    "--------       -----\n",
    "accuracy       100\n",
    "accuracy       80\n",
    "selfdefeating  2.2\n",
    "selfenhancing  3.1\n",
    "selfdefeating  1.1\n",
    "...\n",
    "```\n",
    "\n",
    "** `value` is at the top level of the header hierarchy because the unique `variable` column items correspond to a subset of the `value` column numbers.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F.2.3** Print out the ```.index.names``` property of your wide data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the names include `gender` and `age`. These correspond to the leftmost part of the ```.head()``` printout, which contains the row indices (that are also hierarchical in this case). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### F.3: Indexing With a MultiIndex: Alternative Methods\n",
    "\n",
    "`pandas` provides many different ways to index a DataFrame with a MultiIndex. For now, we'll cover the three I find most intuitive:\n",
    "\n",
    "1. Using **```.xs()```**, which is the \"cross-section\" indexing function.\n",
    "2. Using a **```pd.IndexSlice```** object.\n",
    "3. Using the **```.query()```** function.\n",
    "\n",
    "Let's start with the cross-section function.\n",
    "\n",
    "**F.3.1** Type the following, replacing `value_count_means` with your wide DataFrame name.\n",
    "\n",
    "```python\n",
    "value_count_means.xs(3, level='gender')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F.3.2** The `.xs()` function pulls out value `20` at the index level `age`. So, it is subsetting the data to be everything that corresponds to `age == 20`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F.3.3** First, remove the `value` column index, making the columns non-hierarchical.\n",
    "\n",
    "Then, type the following in Python and explain what is happening and why:\n",
    "\n",
    "```python\n",
    "value_count_means.xs((21, 'male'), level='age', axis=0, drop_level=False)[['aggressive','affiliative']]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F.3.3** The cross section is pulled out along multiple indices using lists/tuples for the section and levels argument. `axis=0` is saying to perform this action on the row indices (`axis=1` would mean your parameters are referring to column indices). `drop_levels=False` is keeping the indices in the return value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**F.3.4** Let's try out the `.query()` function for DataFrames. `.query()` is helpful because it allows us to enter in expressions as intuitive strings.\n",
    "\n",
    "Try out the following `.query()` examples:\n",
    "\n",
    "```dislike_mean_humor``` scores for males with ages that are only 18, 25, or 30.\n",
    "\n",
    "```python\n",
    "value_count_means.query('(gender == male) and (age in [18, 25, 30)')[['dislike_mean_humor']]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get very detailed with these conditionals.\n",
    "\n",
    "Try a query in which, multiplied by each other, `aggressive`, `affiliative`, `self-defeating`, and `self-enhancing` are less than the subject's `age` (and subset to those humor descriptor columns, too).\n",
    "\n",
    "```python\n",
    "value_count_means.query('(aggresive*affiliative*selfenhancing*selfdefeating) > age')[['aggresive','affiliative','selfenhancing','selfdefeating']]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "You can find out more about MultiIndex and advanced indexing below. **This is highly recommended reading!**\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/advanced.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### F.4 Flattening a MultiIndex DataFrame\n",
    "\n",
    "The MultiIndex is a powerful tool, but if you are feeling overwhelmed and want to go back to standard indexed data, you can.\n",
    "\n",
    "You can use **```.reset_index()```** or **`.to_records()`** to reach the same eventual result.\n",
    "\n",
    "Try it out on the wide data below using the following:\n",
    "\n",
    "```python\n",
    "value_count_means.reset_index()\n",
    "pd.DataFrame(value_count_means.to_records())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of `.reset_index()`, your index is now called `variable.` With `.to_records()`, the index is simply the standard integer labels for rows. All the hierarchical indices have been flattened down into columns.\n",
    "\n",
    "Check out the ```.columns```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
